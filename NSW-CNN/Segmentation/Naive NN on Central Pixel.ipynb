{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import skimage.io\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Metric/')\n",
    "from Metric import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top-left coordinate should be of shape (n, 2)\n",
    "def get_patches(raw_image, road_mask, topleft_coordinate, step):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for coord in topleft_coordinate:\n",
    "        X.append(raw_image[:, coord[0]:coord[0]+step, coord[1]:coord[1]+step].flatten())\n",
    "        Y.append(road_mask[int(coord[0]+step/2), int(coord[1]+step/2)])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & Reorder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7961, 8091) (7961, 8091)\n",
      "-2000\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "path_raw_image = \"../../Data/090085/090085_20170531.h5\"\n",
    "path_road_mask = \"../../Data/090085/Road_Data/motor_trunk_pri_sec_tert/motor_trunk_pri_sec_tert.tif\"\n",
    "path_topleft_coordinate = \"../../Data/090085/Road_Data/motor_trunk_pri_sec_tert/topleft_coordinate.h5\"\n",
    "\n",
    "raw_image = np.array(h5py.File(path_raw_image)['scene'])\n",
    "raw_image[np.where(raw_image == -9999)] = 0\n",
    "road_mask = skimage.io.imread(path_road_mask)\n",
    "\n",
    "data = h5py.File(path_topleft_coordinate, 'r')\n",
    "topleft_coordinate = np.array(data['topleft_coordinate'])\n",
    "data.close()\n",
    "\n",
    "print(raw_image.shape, road_mask.shape)\n",
    "print(raw_image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17154396,) (12865797,) (4288599,)\n"
     ]
    }
   ],
   "source": [
    "# Construct training & test set\n",
    "index_mask = np.arange(topleft_coordinate.shape[0])\n",
    "np.random.shuffle(index_mask)\n",
    "\n",
    "train_index = index_mask[:int(index_mask.size*0.75)]\n",
    "test_index = index_mask[int(index_mask.size*0.75):]\n",
    "\n",
    "print(index_mask.shape, train_index.shape, test_index.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 28\n",
    "height = 28\n",
    "band = 7\n",
    "\n",
    "L1_out = 512\n",
    "L2_out = 256\n",
    "L3_out = 128\n",
    "L4_out = 64\n",
    "class_output = 1 # number of possible classifications for the problem\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 9e-6\n",
    "iteration = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Normalization Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5488,) (5488,)\n"
     ]
    }
   ],
   "source": [
    "# Normalize Parameters\n",
    "mu = 0\n",
    "sigma = 0\n",
    "step = width\n",
    "for idx in train_index:\n",
    "    img_idx = topleft_coordinate[idx]\n",
    "    cur_img = raw_image[:, img_idx[0]:img_idx[0]+step, img_idx[1]:img_idx[1]+step].flatten()\n",
    "    mu += cur_img\n",
    "mu = mu / train_index.size\n",
    "\n",
    "for idx in train_index:\n",
    "    img_idx = topleft_coordinate[idx]\n",
    "    cur_img = raw_image[:, img_idx[0]:img_idx[0]+step, img_idx[1]:img_idx[1]+step].flatten()\n",
    "    sigma += (cur_img-mu)**2\n",
    "sigma = sigma / train_index.size\n",
    "\n",
    "print(mu.shape, sigma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place holders for inputs and outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, width*height*band], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, class_output], name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([width*height*band, L1_out], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.truncated_normal([L1_out], stddev=0.1))\n",
    "\n",
    "fc1=tf.matmul(x, W_fc1) + b_fc1 # applying weights and biases\n",
    "h_fc1 = tf.nn.relu(fc1) # ReLU activation\n",
    "\n",
    "# Layer 2\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([L1_out, L2_out], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.truncated_normal([L2_out], stddev=0.1))\n",
    "\n",
    "fc2=tf.matmul(h_fc1, W_fc2) + b_fc2# applying weights and biases\n",
    "h_fc2 = tf.nn.relu(fc2) # ReLU activation\n",
    "\n",
    "# Layer 3\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([L2_out, L3_out], stddev=0.1))\n",
    "b_fc3 = tf.Variable(tf.truncated_normal([L3_out], stddev=0.1))\n",
    "\n",
    "fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(fc3) # ReLU activation\n",
    "\n",
    "# Layer 4\n",
    "W_fc4 = tf.Variable(tf.truncated_normal([L3_out, L4_out], stddev=0.1))\n",
    "b_fc4 = tf.Variable(tf.truncated_normal([L4_out], stddev=0.1))\n",
    "\n",
    "fc4=tf.matmul(h_fc3, W_fc4) + b_fc4\n",
    "h_fc4 = tf.nn.relu(fc4) # ReLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer (Softmax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc_out = tf.Variable(tf.truncated_normal([L4_out, class_output], stddev=0.1))\n",
    "b_fc_out = tf.Variable(tf.truncated_normal([class_output], stddev=0.1))\n",
    "\n",
    "fc_out = tf.matmul(h_fc4, W_fc_out) + b_fc_out\n",
    "\n",
    "y_CNN = tf.sigmoid(fc_out, name='y_CNN')\n",
    "prediction = tf.cast(tf.round(y_CNN), tf.int32, name='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function & optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum((y * tf.log(y_CNN) + (1-y) * tf.log(1-y_CNN)), axis=1))\n",
    "cross_entropy_sum = -tf.reduce_sum(y * tf.log(y_CNN)+(1-y) * tf.log(1-y_CNN))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y, tf.round(y_CNN)), \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & monitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_num = int(train_index.size/batch_size)\n",
    "\n",
    "learning_curve = []\n",
    "for i in range(iteration):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > train_index.size:\n",
    "        end = train_index.size\n",
    "        np.random.shuffle(train_index)\n",
    "\n",
    "    index = train_index[start:end]\n",
    "    batch_x, batch_y = get_patches(raw_image, road_mask, topleft_coordinate[index], step=width)\n",
    "    batch = [((batch_x-mu)/sigma), np.matrix(batch_y).astype(int).T]\n",
    "\n",
    "    # snap shot\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "        learning_curve.append(train_accuracy)\n",
    "        \n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHL1JREFUeJzt3XuYXHWd5/H3pztXMASSNLdcIRedyE0JFxEl3DQgElzR\nAVQcZ5FBgQWedRdmZp91Hcd5xvFZYVUkIqKgIuoiympmMCAYkYskXISAIRcISbgkIYRAQqrr8t0/\n6lSnuruqq5JUd3NOPq/nyZOuc07V+f368ulff8+vzk8RgZmZZUvbYDfAzMxaz+FuZpZBDnczswxy\nuJuZZZDD3cwsgxzuZmYZ5HC3ASHpOUmnDMJ535B08ECf12ywDRnsBpj1p4h422C3wWwweORuqSWp\nfbDb0CqSPNCylnK424CS1CbpKkkrJL0i6WeSxlTt/7mklyS9JmmhpHdW7fuBpOskzZe0BTgx2Xat\npN9Iel3SQ5KmVj0nJE2ren5fx35A0tLk3N+W9HtJFzTRp89Kejp5zackvbvnuavO/8/Jx7MlrZF0\npaSXgO8nr3FG1fFDJK2ver1jJd0vaZOkxyXN3qkvgu0WHO420C4FzgJOAA4EXgWurdr/78B0YF/g\nEeDHPZ5/HvAVYBRwX7LtHOBLwD7A8mR/PTWPlTQO+L/A3wNjgaXAcY06I+ljwP8Czgf2As4EXmn0\nvMT+wBhgMnAh8BPg3Kr9HwQ2RMQjksYDvwH+OXnOF4DbJHU0eS7bzTjcbaBdBPxjRKyJiBzlYDy7\nUpaIiBsj4vWqfYdLGl31/F9FxB8johQR25Jtt0fEnyKiQPmXwRF9nL/esacDSyLiF8m+bwAvNdGf\nC4B/i4iHo2x5RKxq5hMBlIAvRkQuIt4EbgHOlLRHsv88yoEP8ElgfkTMT/q+AFiUtNusF4e7DbTJ\nwO1JaWET8DRQBPaT1C7pX5OSzWbgueQ546qev7rGa1aH8Fagr4uo9Y49sPq1o3xHvTVN9GcisKKJ\n42pZX/ULiohYTvnz8eEk4M+kHPhQ/rx9rPJ5Sz53xwMH7OS5LeN8EccG2mrgbyPijz13SPoUMBc4\nhXKwj6ZctlHVYf11G9MXgQlVbVH14z6sBqbW2bcV2KPq8f50/4VRqy+V0kwb8FQS+JXz/DAiPttE\nm8w8crcBNw/4iqTJAJI6JM1N9o0CcpRr1nsA/zKA7foNcKiks5IS0cWUw7iRG4AvSDpSZdMqfQMe\nA85L/iKZQ/k6QyO3Ah8APsf2UTvAjyiP6D+YvN6I5KJsM7+AbDfkcLeB9n+AO4DfSnodeBA4Jtl3\nM7AKWAs8lewbEBGxAfgY8G+Uf7nMpFzTzjV43s8pX5S9BXgd+CXlC54AlwEfBjYBn0j2NWrHi8AD\nlC/m/rRq+2rKf9X8A7Ce8kj+v+GfYatDXqzDrDdJbZRLKJ+IiHsGuz1mO8q/9c0SScljb0nDKY+Q\nxQD+9WDWSg53s+3eQ3nmywbK5ZSzIuJNSfOSe9T0/DdvcJtrVp/LMmZmGeSRu5lZBg3aPPdx48bF\nlClTBuv0ZmaptHjx4g0R0fC2E4MW7lOmTGHRokWDdXozs1SS1NTtLVyWMTPLIIe7mVkGOdzNzDLI\n4W5mlkEOdzOzDGoY7pJulLRO0pN19kvSNyQtl/TnypJgZmY2eJoZuf8AmNPH/tMoL4s2nfJSYdft\nerPMzGxXNJznHhELJU3p45C5wM3JyjUPJjdeOiC5demAiQh++OAqNrxe+w6txxw8luOmjqW8BkPf\nHn3+Ve5dup4duTWDJE6duR+HjB/d8NiIYOGyDWza2slphxzAsCE7Xx17I1fgtsVreOWNPu9M238k\n3jt1LMccPHaXXubZDVv49eMvkC+WWtKsgzr25IzDDmRoe+PP7ZpXt/Krx14gly+25NwzDxzNnEOa\nuRU8vNlZ5McPrWLzm/neOyVOmDGOIyeP6b2vhgdXvsKaV9/kjMMOYMTQ9obHb3gjx22L17AlV2jq\n9d8KJo/dkzOPaO7rWs/r2/LctngNG7d0trBlO2bWlDG8f0b/Ln/b1L1lknD/dUQcUmPfr4F/jYj7\nksd3A1dGRK93KEm6kPLonkmTJh25alWzS002tubVrRz/1XuS83TfV+niUVP24YpTZ3Dc1HHU8vjq\nTVx91zPcu3R9zdfpS+UcH5i5H5efMoOZB+5V45jg98+s5+q7lvH46k0AjN97JJeeNI2PHjlhh75h\nt+QK3PTAc3x34Upe3Zrfoba2UqXf7zl4LFecOoOjD2ouiCpWvbKFb/5uObc/upZiKVrSj0qbJo/d\ng0tPms5ZRxzIkBqf27Wb3uTae5bz80WryRdbe+7/8aG/4oL3HdznsdvyRS64aRH3Ld9Q89yV13rf\n9HFcceoM3j1pn5qv89DKV7j6rmd4cOVGAPYdNZzPzZ7KuUdPqhnyG7d08p2FK7j5/lW8mS8O2vfO\njqp8PiaOGcmlJ07nI+8ev0M/M2/kCtx0/3N89w8r2TSIPzMAF50wlSvnvGOnnitpcUTManjcQIZ7\ntVmzZkUr36G67OXXOfXqhXzrvHdxxmEHdtuXKxT52cOr+dY9y3l5c45jDhrDFafO4NhktPnk2te4\nesEz3P2Xdey9x1AufP/BfPo9U9hzePNv4N28Lc+N9z3L9+57lte3FTjtkP25/JQZvH3/UUQE9y3f\nwNcXPMOjz2/qCvT9Ro/gmiToJ44ZyaUnTec/vWt8zSCq2NpZ4IcPrOI7C1eycUsns9/eweWnzOCI\niXvv3CduF23LF7nloef59r0r2PBGjuOnjeOKU6c3HG2u3riVb/5uGbc9spYhbeKTx07m7044mH1H\njdjlNkUEdz+9jqvveoYlL2zmoHF78l9OnsaZh4+nvU28+NqbfPueFfz04dUEwTlHTeLzJ07lgNEj\nd/nc+WKJy259lPlPvMQXPzyTz7z3oJrHbcsX+ezN5WD/2tmHc/aRvRdUqvW1vuKUGRyefK0ffm4j\nVy94hvtXvELHqOF8fvZU3r7fKL7xu2U8uHIj++01nItPnMZfHzWR4UPaeXVLJ9/9w0puuv85tuaL\nzD38QC49eTpTO/pacvatIyK4Z+k6rl6wjCfWvtbwl3fFllyBmx9YxfULV/Dq1jwnv2NfLj9lBodO\naPxX9lvRQIb7d4B7I+InyeOlwOxGZZlWh/uTa1/jjG/ex3fPn8WpM/erecy2fJFb//Q81967gvWv\n5zhu6lj2HD6EBU+9zOiRSagfN4W37UCo9/Tam3m+d9+z3Hjfs2zpLHD6IQfw8uZtLFr1KgeOHsEl\nJ03n7CMndJViIoJ7l67n6wue6fqG/fR7pjB65NBer/3S5m18/4/PsuGNTt4/o4PLT5ledzQ30Crl\nhevuXcErW8rtO+OwA2ivMTxatGojP1+0hrY2cd7Rk/j87Knsu9euh3pPEcFvn3qZa+5axtMvbubg\njj05avIYbn90LaUIPn7URC4+cRrj9971UK+WL5a49JZH+Y8lL/GlM9/Jp4+b0m3/tnyRv/vhYhYu\nW89XP3oYH581sc/Xq4TTdxauYFMSTp3FEn9YtoFxbyuP0j9xTPdR+v0rNnDNgmX86bmNHDB6BCe+\nY1/ueOwFtnQWOOOwA7ns5GlM23dUS/s9UGr98j7/PZPZa0Tvn5kXX3uTG//43FtiINQqAxnuHwIu\nAU6nvFzaNyLi6Eav2epwX7xqIx+97gFu/tujG9aytuWL/Pih57nu3hV0Fopc8L6D+Zv3Tqn5zbGz\nNm3t5IY/PMv3//gso0YM5eKTpvHxWRMYPqR2LbTnN2w9zY6MB0vP0WYtw9rbOPfoiXxu9jT2H936\nUO+pVAp++9RLXHPXMpave4Ozj5zAxSdOY+KYPRo/eSd1Fkpccssj/Papl/nyWYfwqWPLy6rmCkUu\n+uFi7lm6nq9+9FD++qhJTb9mpaxw/cKVDGkTF50wlU8eO5mRw+p/T92/4hW+vuAZFq96lQ8degCX\nnTKdGfulM9R76vnLu55GZa20aVm4S/oJMBsYB7wMfBEYChAR85JV4r9FeUbNVuAzjUoy0Ppwv3/5\nBs674SF+euGxTV/cyxdLRLBLFzQbyRWKtEt9/tlYLSJYu+lNSjWuKw4b0jYgYdgK2/JF1m2ufZF3\n9MihjN6jdb9Im1UqBZ3FUlMXG1uhs1Di8z9+hLuefpmvfOQQzj5yAp//0SPc/Zd1/MtHDuW8Y5oP\n9p6vK9F0vTki2JYv1f0lkHalUvlnplaUpelnplnNhnszs2XObbA/KK8UP6hyhXIaDt+BH9xdueLe\nrHoj9XokMWGf/htRDpQRQ9uZNPat1Y+2NjGibeACbtiQNq79xLv43I8e4R9vf5JbHnqeJS9s5stn\nHbLTwV553R0hKbPBDuWva3/+FZZWmXmHaq5QnsY2vB9H4WY7aviQdq775Ls58e0dLHlhM/80951d\nJRqz/jRo93Nvta6Ru8Pd3mKGD2nn+vNnseqVrUzbNx0zUyz9MpOEufyOl2XMBsrQ9jYHuw2o7IS7\nyzJmZl0yk4Quy5iZbZeZJNwe7i7LmJllJ9yTe2QMbU/JjTLMzPpRdsK9UGL4kLam7vpoZpZ1GQt3\nl2TMzCBT4V70xVQzs0Rm0jCXLzF8aGa6Y2a2SzKThtsKRZdlzMwSmQn3XL7ksoyZWSIzaViZLWNm\nZpkKd5dlzMwqMhTuvqBqZlaRmTR0zd3MbLvMpKHLMmZm22Uo3EuMcFnGzAzIWLh75G5mVpadcM/7\n9gNmZhWZSUPPljEz2y4TaVgoliiUwmUZM7NEJsK9s+gl9szMqmUiDXN5h7uZWbVMpGHX+qlDXZYx\nM4PMhHsR8MjdzKwiE2nYNXL3BVUzMyAr4e6au5lZN5lIw66yjOe5m5kBmQl3l2XMzKo1Fe6S5kha\nKmm5pKtq7B8t6f9JelzSEkmfaX1T6/MFVTOz7hqmoaR24FrgNGAmcK6kmT0Ouxh4KiIOB2YD/1vS\nsBa3ta6umrvLMmZmQHMj96OB5RGxMiI6gVuBuT2OCWCUJAFvAzYChZa2tA8uy5iZdddMuI8HVlc9\nXpNsq/Yt4K+AF4AngMsiotTzhSRdKGmRpEXr16/fySb3ti3vsoyZWbVWpeEHgceAA4EjgG9J2qvn\nQRFxfUTMiohZHR0dLTp19cjd4W5mBs2F+1pgYtXjCcm2ap8BfhFly4FngXe0pomNbZ8K6bKMmRk0\nF+4PA9MlHZRcJD0HuKPHMc8DJwNI2g94O7CylQ3ti9/EZGbW3ZBGB0REQdIlwJ1AO3BjRCyRdFGy\nfx7wZeAHkp4ABFwZERv6sd3d5Aol2gRD2jRQpzQze0trGO4AETEfmN9j27yqj18APtDapjUvVygy\nfEg75ck6ZmaWiTqGl9gzM+suE4mYy5cY4TnuZmZdshHuhaJH7mZmVTKRiLlCyTNlzMyqZCIRy+Hu\nsoyZWUVGwr3okbuZWZVMJGIu79kyZmbVMpGILsuYmXWXkXB3WcbMrFomEtGzZczMustEIubyLsuY\nmVXLRrj7TUxmZt1kIhFdljEz6y4TiejZMmZm3aU+3AvFEsVSeORuZlYl9YnYtX6qa+5mZl1Sn4jb\nF8d2WcbMrCL14b4tnyyO7bKMmVmX1CeiyzJmZr2lPhFzhcrI3WUZM7OK9Id7vlJzT31XzMxaJvWJ\n6AuqZma9ZSDck7KMa+5mZl1Sn4guy5iZ9Zb6RHRZxsystwyEe7ksM8JlGTOzLqlPRI/czcx6S3+4\n+x2qZma9pD4R/Q5VM7PeUp+IlXAf1p76rpiZtUzqEzFXKDKkTQxxuJuZdWkqESXNkbRU0nJJV9U5\nZrakxyQtkfT71jazvvLi2A52M7NqQxodIKkduBY4FVgDPCzpjoh4quqYvYFvA3Mi4nlJ+/ZXg3vK\nFUoMH+qZMmZm1ZoZ8h4NLI+IlRHRCdwKzO1xzHnALyLieYCIWNfaZtaXKxQ9cjcz66GZVBwPrK56\nvCbZVm0GsI+keyUtlnR+qxrYSHlxbIe7mVm1hmWZHXidI4GTgZHAA5IejIhnqg+SdCFwIcCkSZNa\ncuJyzd1lGTOzas0MedcCE6seT0i2VVsD3BkRWyJiA7AQOLznC0XE9RExKyJmdXR07Gybu8kVip7j\nbmbWQzOp+DAwXdJBkoYB5wB39DjmV8DxkoZI2gM4Bni6tU2tzWUZM7PeGpZlIqIg6RLgTqAduDEi\nlki6KNk/LyKelvQfwJ+BEnBDRDzZnw2vyBVKjPRsGTOzbpqquUfEfGB+j23zejz+GvC11jWtOblC\nkb1HDh3o05qZvaWlvp6xLV9yzd3MrIfUp2J5nrvLMmZm1dIf7r79gJlZL6lPRc+WMTPrLfWpWJ7n\n7rKMmVm1VId7RHjkbmZWQ6pTMV8MIrzEnplZT6lOxVyhsn6qyzJmZtVSHu7lJfZGeJ67mVk3qU7F\nrsWxPXI3M+sm3eGeT8oyHrmbmXWT6lTcPnJPdTfMzFou1anosoyZWW3pDvdKWcYjdzOzblKdil0j\nd9fczcy6SXUquixjZlZbysPdZRkzs1pSnYq5vEfuZma1pDvcXXM3M6sp1anosoyZWW2pTkVfUDUz\nqy3d4Z7U3Id55G5m1k2qUzFXKDK0XbS3abCbYmb2lpLqcN+WL7kkY2ZWQ6rDPVco+mKqmVkNqU5G\nr59qZlZbqpMxVygxfKjLMmZmPaU73PMuy5iZ1ZLqZHRZxsystlQnY/mCqssyZmY9pTzcS76vjJlZ\nDalOxlzeZRkzs1qaSkZJcyQtlbRc0lV9HHeUpIKks1vXxPpyhaJny5iZ1dAw3CW1A9cCpwEzgXMl\nzaxz3FeB37a6kfX4gqqZWW3NJOPRwPKIWBkRncCtwNwax10K3Aasa2H7+lQOd4/czcx6aibcxwOr\nqx6vSbZ1kTQe+AhwXV8vJOlCSYskLVq/fv2OtrUXz3M3M6utVcl4DXBlRJT6Oigiro+IWRExq6Oj\nY5dP6tkyZma1DWnimLXAxKrHE5Jt1WYBt0oCGAecLqkQEb9sSStriAiXZczM6mgm3B8Gpks6iHKo\nnwOcV31ARBxU+VjSD4Bf92ewA3QWK6sweeRuZtZTw3CPiIKkS4A7gXbgxohYIumiZP+8fm5jTduX\n2HO4m5n11MzInYiYD8zvsa1mqEfE3+x6sxqrLLHnee5mZr2ldtibKxQBj9zNzGpJbTK6LGNmVl9q\nk7GrLOPZMmZmvaQ33CtlGc9zNzPrJbXJ6LKMmVl9qU3GbfnKBVWXZczMekptuHvkbmZWX2qTsRLu\nI1xzNzPrJbXJmHNZxsysrvSGu8syZmZ1pTYZt4e7R+5mZj2lONw9z93MrJ7UJmPlHarD2lPbBTOz\nfpPaZMwVSgxrb6OtTYPdFDOzt5wUh3vRJRkzszpSm45eYs/MrL70hnu+5GmQZmZ1pDYdXZYxM6sv\ntenosoyZWX0pD/fUNt/MrF+lNh1z+aLD3cysjtSmY65QYvhQl2XMzGpJd7h75G5mVlNq0zFXcFnG\nzKye1KZjeZ67yzJmZrWkN9wLJc9zNzOrI7Xp6LKMmVl9qU1Hv4nJzKy+VIZ7qRR0eraMmVldqUzH\nzmKyxJ5r7mZmNaUyHSurMLksY2ZWW1PhLmmOpKWSlku6qsb+T0j6s6QnJN0v6fDWN3W7rvVTXZYx\nM6upYTpKageuBU4DZgLnSprZ47BngRMi4lDgy8D1rW5otVyhMnJ3uJuZ1dJMOh4NLI+IlRHRCdwK\nzK0+ICLuj4hXk4cPAhNa28zuukbuvreMmVlNzYT7eGB11eM1ybZ6/jPw77V2SLpQ0iJJi9avX998\nK3vYlvfI3cysLy1NR0knUg73K2vtj4jrI2JWRMzq6OjY6fO4LGNm1rchTRyzFphY9XhCsq0bSYcB\nNwCnRcQrrWlebdsvqLosY2ZWSzND34eB6ZIOkjQMOAe4o/oASZOAXwCfiohnWt/M7rpG7p7nbmZW\nU8ORe0QUJF0C3Am0AzdGxBJJFyX75wH/ExgLfFsSQCEiZvVXoyvz3Ed45G5mVlMzZRkiYj4wv8e2\neVUfXwBc0Nqm1bd9toxH7mZmtaQyHX1B1cysb6lMx+3h7rKMmVkt6Qz3vMsyZmZ9SWU6uixjZta3\nVKZjJdyHtaey+WZm/S6V6VhZYi+ZdmlmZj2kM9zzXoXJzKwvqUzIXKHkO0KamfUhpeFe9MjdzKwP\nqUzInBfHNjPrUyoTslxzd1nGzKyedIZ7oeg3MJmZ9SGVCenZMmZmfUtlQpYvqLosY2ZWT0rD3SN3\nM7O+pDIhPc/dzKxv6Qz3vOe5m5n1JZUJ6bKMmVnfUpmQ5XB3WcbMrJ6UhrvnuZuZ9SV1CVksBfli\nuCxjZtaH1CVkZ7JQxwjPljEzqyt14Z4rJOuneuRuZlZX6hJy+/qpHrmbmdWTvnDPe3FsM7NGUpeQ\nXWUZz5YxM6srdQnpsoyZWWMpDHdfUDUzayR1Cemau5lZY6lLyK6yjOe5m5nVlcJwd1nGzKyRphJS\n0hxJSyUtl3RVjf2S9I1k/58lvbv1TS3rGDWc0w/dn733GNpfpzAzS70hjQ6Q1A5cC5wKrAEelnRH\nRDxVddhpwPTk3zHAdcn/LXfk5DEcOXlMf7y0mVlmNDNyPxpYHhErI6ITuBWY2+OYucDNUfYgsLek\nA1rcVjMza1Iz4T4eWF31eE2ybUePQdKFkhZJWrR+/fodbauZmTVpQK9KRsT1ETErImZ1dHQM5KnN\nzHYrzYT7WmBi1eMJybYdPcbMzAZIM+H+MDBd0kGShgHnAHf0OOYO4Pxk1syxwGsR8WKL22pmZk1q\nOFsmIgqSLgHuBNqBGyNiiaSLkv3zgPnA6cByYCvwmf5rspmZNdIw3AEiYj7lAK/eNq/q4wAubm3T\nzMxsZ/ltnmZmGaTyoHsQTiytB1bt5NPHARta2Jw02V377n7vXtzv+iZHRMPphoMW7rtC0qKImDXY\n7RgMu2vf3e/di/u961yWMTPLIIe7mVkGpTXcrx/sBgyi3bXv7vfuxf3eRamsuZuZWd/SOnI3M7M+\nONzNzDIodeHeaFWorJB0o6R1kp6s2jZG0gJJy5L/9xnMNvYHSRMl3SPpKUlLJF2WbM903yWNkPQn\nSY8n/f5Ssj3T/a6Q1C7pUUm/Th5nvt+SnpP0hKTHJC1KtrWs36kK96pVoU4DZgLnSpo5uK3qNz8A\n5vTYdhVwd0RMB+5OHmdNAfivETETOBa4OPkaZ73vOeCkiDgcOAKYk9yEL+v9rrgMeLrq8e7S7xMj\n4oique0t63eqwp3mVoXKhIhYCGzssXkucFPy8U3AWQPaqAEQES9GxCPJx69T/oEfT8b7nqxi9kby\ncGjyL8h4vwEkTQA+BNxQtTnz/a6jZf1OW7g3teJThu1XdSvll4D9BrMx/U3SFOBdwEPsBn1PShOP\nAeuABRGxW/QbuAb470Cpatvu0O8A7pK0WNKFybaW9bupu0LaW09EhKTMzmOV9DbgNuDyiNgsqWtf\nVvseEUXgCEl7A7dLOqTH/sz1W9IZwLqIWCxpdq1jstjvxPERsVbSvsACSX+p3rmr/U7byH13X/Hp\n5crC48n/6wa5Pf1C0lDKwf7jiPhFsnm36DtARGwC7qF8zSXr/X4vcKak5yiXWU+S9COy328iYm3y\n/zrgdspl55b1O23h3syqUFl2B/Dp5ONPA78axLb0C5WH6N8Dno6Ir1ftynTfJXUkI3YkjQROBf5C\nxvsdEX8fERMiYgrln+ffRcQnyXi/Je0paVTlY+ADwJO0sN+pe4eqpNMp1+gqq0J9ZZCb1C8k/QSY\nTfkWoC8DXwR+CfwMmET5dskfj4ieF11TTdLxwB+AJ9heg/0HynX3zPZd0mGUL6C1Ux50/Swi/knS\nWDLc72pJWeYLEXFG1vst6WDKo3Uol8dviYivtLLfqQt3MzNrLG1lGTMza4LD3cwsgxzuZmYZ5HA3\nM8sgh7uZWQY53M3MMsjhbmaWQf8fR7eYLlNq6p4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b693d99b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curve\n",
    "plt.figsize=(9,5)\n",
    "plt.plot(learning_curve)\n",
    "plt.title('learning_curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = './Result/motor_trunk_pri_sec_tert/'\n",
    "model_name = 'motor_trunk_pri_sec_tert'\n",
    "saver.save(sess, save_path + model_name)\n",
    "\n",
    "h5f = h5py.File(save_path + \"training_info.h5\", 'w')\n",
    "\n",
    "h5f_Index = h5f.create_group(\"Index\")\n",
    "h5f_Index.create_dataset(name='train_index', shape=train_index.shape, data=train_index)\n",
    "h5f_Index.create_dataset(name='test_index', shape=test_index.shape, data=test_index)\n",
    "\n",
    "h5f_Norm = h5f.create_group(\"Norm\")\n",
    "h5f_Norm.create_dataset(name='mu', shape=mu.shape, data=mu)\n",
    "h5f_Norm.create_dataset(name='sigma', shape=sigma.shape, data=sigma)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0f5e0c06b2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_num\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Metric' is not defined"
     ]
    }
   ],
   "source": [
    "train_metric = Metric()\n",
    "\n",
    "batch_num = int(train_index.size/batch_size)+1\n",
    "for i in range(batch_num):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > train_index.size:\n",
    "        end = train_index.size\n",
    "    \n",
    "    index = train_index[start:end]\n",
    "    batch_x, batch_y = get_patches(raw_image, road_mask, topleft_coordinate[index], step=width)\n",
    "    batch = [((batch_x-mu)/sigma), np.matrix(batch_y).astype(int).T]\n",
    "    \n",
    "    # record metric\n",
    "    pred = prediction.eval(feed_dict={x:batch[0]})\n",
    "    train_metric.accumulate(pred, batch[1])\n",
    "    \n",
    "train_metric.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_pos  = 0\n",
      "false_pos = 16548\n",
      "true_neg  = 4272051\n",
      "false_neg = 0\n",
      "size = 4288599\n",
      "pos_recall    = nan\n",
      "pos_precision = 0.0\n",
      "pos_F1        = nan\n",
      "neg_precision = 1.0\n",
      "neg_recall    = 0.996141397226\n",
      "neg_F1        = 0.998066969214\n",
      "accuracy      = 0.996141397226\n",
      "16548.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Metric/Metric.py:50: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  pos_recall = true_pos / (true_pos + false_neg)\n"
     ]
    }
   ],
   "source": [
    "test_metric = Metric()\n",
    "\n",
    "batch_num = int(test_index.size/batch_size)+1\n",
    "for i in range(batch_num):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > test_index.size:\n",
    "        end = test_index.size\n",
    "    \n",
    "    index = test_index[start:end] \n",
    "    batch_x, batch_y = get_patches(raw_image, road_mask, topleft_coordinate[index], step=width)\n",
    "    batch = [((batch_x-mu)/sigma), np.matrix(batch_y).astype(int).T]\n",
    "\n",
    "    # record metric   \n",
    "    pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})        \n",
    "    test_metric.accumulate(pred, batch[1])\n",
    "    \n",
    "test_metric.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
