{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import scipy.io as sio\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(path, input_size, Layer_out, class_output, batch_size, learning_rate, iteration):\n",
    "    \n",
    "    # Read in data\n",
    "    data = h5py.File(path, 'r')\n",
    "    X = np.array(data['image_patch'])\n",
    "    Y = np.array(data['road_existence'])\n",
    "    data.close()\n",
    "\n",
    "    # Reorder & Create masks\n",
    "    index_mask = np.arange(X.shape[0])\n",
    "    np.random.shuffle(index_mask)\n",
    "\n",
    "    train_mask = index_mask[:int(index_mask.size*0.75)]\n",
    "    test_mask = index_mask[int(index_mask.size*0.75):]\n",
    "\n",
    "    train_x = X[train_mask].flatten().reshape((train_mask.size, -1))\n",
    "    train_y = Y[train_mask]\n",
    "    train_mask = np.arange(train_x.shape[0])\n",
    "    np.random.shuffle(train_mask)\n",
    "\n",
    "    test_x = X[test_mask].flatten().reshape((test_mask.size, -1))\n",
    "    test_y = Y[test_mask]\n",
    "    test_mask = np.arange(test_x.shape[0])\n",
    "    np.random.shuffle(test_mask)\n",
    "\n",
    "    # Normalize Parameters\n",
    "    mu = train_x.mean(axis=0, keepdims=True)\n",
    "    sigma = 0\n",
    "    for img in train_x:\n",
    "        sigma += (img-mu)**2\n",
    "    sigma /= train_x.shape[0]\n",
    "\n",
    "    # layer parameter\n",
    "    L1_out = Layer_out[1]\n",
    "    L2_out = Layer_out[2]\n",
    "    L3_out = Layer_out[3]\n",
    "    L4_out = Layer_out[4]\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, class_output])\n",
    "\n",
    "    # Layer 1\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal([input_size, L1_out], stddev=0.1))\n",
    "    b_fc1 = tf.Variable(tf.truncated_normal([L1_out], stddev=0.1))\n",
    "\n",
    "    fc1=tf.matmul(x, W_fc1) + b_fc1 # applying weights and biases\n",
    "    h_fc1 = tf.nn.relu(fc1) # ReLU activation\n",
    "\n",
    "    # Layer 2\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([L1_out, L2_out], stddev=0.1))\n",
    "    b_fc2 = tf.Variable(tf.truncated_normal([L2_out], stddev=0.1))\n",
    "\n",
    "    fc2=tf.matmul(h_fc1, W_fc2) + b_fc2# applying weights and biases\n",
    "    h_fc2 = tf.nn.relu(fc2) # ReLU activation\n",
    "\n",
    "    # Layer 3\n",
    "    W_fc3 = tf.Variable(tf.truncated_normal([L2_out, L3_out], stddev=0.1))\n",
    "    b_fc3 = tf.Variable(tf.truncated_normal([L3_out], stddev=0.1))\n",
    "\n",
    "    fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "    h_fc3 = tf.nn.relu(fc3) # ReLU activation\n",
    "\n",
    "    # Layer 4\n",
    "    W_fc4 = tf.Variable(tf.truncated_normal([L3_out, L4_out], stddev=0.1))\n",
    "    b_fc4 = tf.Variable(tf.truncated_normal([L4_out], stddev=0.1))\n",
    "\n",
    "    fc4=tf.matmul(h_fc3, W_fc4) + b_fc4\n",
    "    h_fc4 = tf.nn.relu(fc4) # ReLU activation\n",
    "\n",
    "    W_fc_out = tf.Variable(tf.truncated_normal([L4_out, class_output], stddev=0.1))\n",
    "    b_fc_out = tf.Variable(tf.truncated_normal([class_output], stddev=0.1))\n",
    "\n",
    "    fc_out=tf.matmul(h_fc4, W_fc_out) + b_fc_out\n",
    "\n",
    "    y_CNN= tf.sigmoid(fc_out)\n",
    "    prediction = tf.cast(tf.round(y_CNN), tf.int32)\n",
    "\n",
    "    cross_entropy = -tf.reduce_mean(tf.reduce_sum((y * tf.log(y_CNN) + (1-y) * tf.log(1-y_CNN)), axis=1))\n",
    "    cross_entropy_sum = -tf.reduce_sum(y * tf.log(y_CNN)+(1-y) * tf.log(1-y_CNN))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_sum)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y, tf.round(y_CNN)), \"float\"))\n",
    "\n",
    "    batch_num = int(train_mask.size/batch_size)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # start training\n",
    "    learning_curve = []\n",
    "    F1_curve = []\n",
    "    for i in range(iteration):\n",
    "        start = i%batch_num * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        if end > train_mask.size:\n",
    "            end = train_mask.size\n",
    "            np.random.shuffle(train_mask)\n",
    "\n",
    "        train_index = train_mask[start:end]    \n",
    "        batch = [((train_x[train_index]-mu)/sigma), np.matrix(train_y[train_index]).astype(int).T]\n",
    "\n",
    "        # snap shot\n",
    "        if i%1000 == 0:\n",
    "            pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "\n",
    "            # compute metric\n",
    "            true_neg = np.logical_and(pred == batch[1], np.logical_not(batch[1])).sum()\n",
    "            false_neg = (np.logical_not(batch[1]).sum()) - true_neg\n",
    "            true_pos = (np.logical_and(pred == batch[1], batch[1])).sum()\n",
    "            false_pos = batch[1].sum() - true_pos\n",
    "\n",
    "            precision = true_neg / (true_neg + false_neg)\n",
    "            recall = true_neg / (true_neg + false_pos)\n",
    "\n",
    "            train_F1_score = 2*(recall*precision) / (recall+precision)\n",
    "\n",
    "            learning_curve.append(train_accuracy)\n",
    "            F1_curve.append(train_F1_score)\n",
    "\n",
    "        train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "    # evaluae on training set\n",
    "    train_acc = []\n",
    "    train_F1 = []\n",
    "    batch_num = int(train_mask.size/batch_size)\n",
    "    for i in range(batch_num+1):\n",
    "        start = i%batch_num * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        if end > train_mask.size:\n",
    "            end = train_mask.size\n",
    "\n",
    "        batch = [((train_x[start:end]-mu)/sigma), np.matrix(train_y[start:end]).T]\n",
    "\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "        train_acc.append(train_accuracy * (end-start))\n",
    "\n",
    "        # compute metric   \n",
    "        pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "\n",
    "        true_neg = np.logical_and(pred == batch[1], np.logical_not(batch[1])).sum()\n",
    "        false_neg = (np.logical_not(batch[1]).sum()) - true_neg\n",
    "        true_pos = (np.logical_and(pred == batch[1], batch[1])).sum()\n",
    "        false_pos = batch[1].sum() - true_pos\n",
    "\n",
    "        precision = true_neg / (true_neg + false_neg)\n",
    "        recall = true_neg / (true_neg + false_pos)     \n",
    "\n",
    "        train_F1.append(2*(recall*precision) / (recall+precision)* (end-start))\n",
    "\n",
    "    print(\"train_acc = \", sum(train_acc)/train_mask.size, \" train_F1 = \", sum(train_F1)/train_mask.size)\n",
    "\n",
    "    # evaluae on test set\n",
    "    test_acc = []\n",
    "    test_F1 = []\n",
    "    batch_num = int(test_mask.size/batch_size)\n",
    "    for i in range(batch_num+1):\n",
    "        start = i%batch_num * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        if end > test_mask.size:\n",
    "            end = test_mask.size\n",
    "\n",
    "        batch = [((test_x[start:end]-mu)/sigma), np.matrix(test_y[start:end]).T]\n",
    "\n",
    "        test_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "        test_acc.append(test_accuracy * (end-start))\n",
    "\n",
    "        # compute metric   \n",
    "        pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})        \n",
    "\n",
    "        true_neg = np.logical_and(pred == batch[1], np.logical_not(batch[1])).sum()\n",
    "        false_neg = (np.logical_not(batch[1]).sum()) - true_neg\n",
    "        true_pos = (np.logical_and(pred == batch[1], batch[1])).sum()\n",
    "        false_pos = batch[1].sum() - true_pos\n",
    "\n",
    "        precision = true_neg / (true_neg + false_neg)\n",
    "        recall = true_neg / (true_neg + false_pos)     \n",
    "\n",
    "        test_F1.append(2*(recall*precision) / (recall+precision)* (end-start))\n",
    "\n",
    "    print(\"test_acc  = \", sum(test_acc)/test_mask.size, \"test_F1 = \", sum(test_F1)/test_mask.size)\n",
    "    \n",
    "    # finish the session & clean\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # plot training curve\n",
    "    fig, subfig = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(10,5)) \n",
    "    subfig[0].plot(learning_curve)\n",
    "    subfig[0].title('learning_curve')\n",
    "    \n",
    "    subfig[1].plot(F1_curve)\n",
    "    subfig[1].title('F1_curve')    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data_path in [\"../Data/090085/Road_Data/res_serv_road_livi/patch_set.h5\",\n",
    "                  \"../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl/patch_set.h5\",\n",
    "                  \"../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/patch_set.h5\",\n",
    "                  \"../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track_res_serv_road_livi/patch_set.h5\"]:        \n",
    "    print(data_path)\n",
    "    for i in range(3):\n",
    "        run_experiment(path=data_path,\n",
    "                   input_size=28*28*7, Layer_out=[0, 512, 256, 128, 64], class_output=1,\n",
    "                   batch_size=64, iteration=100000, learning_rate=5e-6)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
