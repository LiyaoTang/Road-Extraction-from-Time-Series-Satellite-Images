{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import scipy.io as sio\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & Reorder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "path = \"../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/patch_set.h5\"\n",
    "\n",
    "data = h5py.File(path, 'r')\n",
    "X = np.array(data['image_patch'])\n",
    "Y = np.array(data['road_existence'])\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256194, 5488) (256194,)\n",
      "(85399, 5488) (85399,)\n"
     ]
    }
   ],
   "source": [
    "# Reorder & Create masks\n",
    "index_mask = np.arange(X.shape[0])\n",
    "np.random.shuffle(index_mask)\n",
    "\n",
    "train_mask = index_mask[:int(index_mask.size*0.75)]\n",
    "test_mask = index_mask[int(index_mask.size*0.75):]\n",
    "\n",
    "train_x = X[train_mask].flatten().reshape((train_mask.size, -1))\n",
    "train_y = Y[train_mask]\n",
    "train_mask = np.arange(train_x.shape[0])\n",
    "np.random.shuffle(train_mask)\n",
    "\n",
    "test_x = X[test_mask].flatten().reshape((test_mask.size, -1))\n",
    "test_y = Y[test_mask]\n",
    "test_mask = np.arange(test_x.shape[0])\n",
    "np.random.shuffle(test_mask)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 28\n",
    "height = 28\n",
    "band = 7\n",
    "\n",
    "L1_out = 1024\n",
    "L2_out = 512\n",
    "L3_out = 256\n",
    "L4_out = 128\n",
    "class_output = 1 # number of possible classifications for the problem\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 9e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Normalization Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize Parameters\n",
    "mu = train_x.mean(axis=0, keepdims=True)\n",
    "sigma = 0\n",
    "for img in train_x:\n",
    "    sigma += (img-mu)**2\n",
    "sigma /= train_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_i$ is the raw number (int)\n",
    "\n",
    "$\\mu = \\frac 1 n \\sum_{i=1}^n \\frac {a_i} {\\text{Max}} = \\frac 1 {\\text{Max}}(\\frac 1 n \\sum_{i=1}^n a_i)$\n",
    "\n",
    "$\\sigma = \\sqrt{\\frac 1 n \\sum_{i=1}^n (\\frac{a_i}{\\text{Max}}-\\mu)^2 } = \\frac 1 {\\text{Max}} \\sqrt{\\frac 1 n \\sum_{i=1}^n(a_i-\\mu*\\text{Max})^2 } $\n",
    "\n",
    "$\\displaystyle \\frac {\\frac A {\\text{Max}} - mu} {\\sigma} = \\frac {A-\\mu *\\text{Max}}{\\sigma *\\text{Max}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place holders for inputs and outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x  = tf.placeholder(tf.float32, shape=[None, width*height*band])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, class_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([width*height*band, L1_out], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.truncated_normal([L1_out], stddev=0.1))\n",
    "\n",
    "fc1=tf.matmul(x, W_fc1) + b_fc1 # applying weights and biases\n",
    "h_fc1 = tf.nn.relu(fc1) # ReLU activation\n",
    "\n",
    "# Layer 2\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([L1_out, L2_out], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.truncated_normal([L2_out], stddev=0.1))\n",
    "\n",
    "fc2=tf.matmul(h_fc1, W_fc2) + b_fc2# applying weights and biases\n",
    "h_fc2 = tf.nn.relu(fc2) # ReLU activation\n",
    "\n",
    "# Layer 3\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([L2_out, L3_out], stddev=0.1))\n",
    "b_fc3 = tf.Variable(tf.truncated_normal([L3_out], stddev=0.1))\n",
    "\n",
    "fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(fc3) # ReLU activation\n",
    "\n",
    "# Layer 4\n",
    "W_fc4 = tf.Variable(tf.truncated_normal([L3_out, L4_out], stddev=0.1))\n",
    "b_fc4 = tf.Variable(tf.truncated_normal([L4_out], stddev=0.1))\n",
    "\n",
    "fc4=tf.matmul(h_fc3, W_fc4) + b_fc4\n",
    "h_fc4 = tf.nn.relu(fc4) # ReLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer (Softmax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc_out = tf.Variable(tf.truncated_normal([L4_out, class_output], stddev=0.1))\n",
    "b_fc_out = tf.Variable(tf.truncated_normal([class_output], stddev=0.1))\n",
    "\n",
    "fc_out=tf.matmul(h_fc4, W_fc_out) + b_fc_out\n",
    "\n",
    "y_CNN= tf.nn.softmax(fc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function & optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * (y_CNN), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_CNN, y_)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & monitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256194, 5488)\n",
      "64\n",
      "4003\n",
      "start\n",
      "step 0     : train_acc = 0.3125   , cross entropy = -0.312500 \n",
      "step 1000  : train_acc = 0.375    , cross entropy = -0.375000 \n"
     ]
    }
   ],
   "source": [
    "batch_num = int(len(train_x)/batch_size)\n",
    "print(train_x.shape)\n",
    "print(batch_size)\n",
    "print(batch_num)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"start\")\n",
    "learning_curve = []\n",
    "for i in range(50000):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > train_mask.size:\n",
    "        end = train_mask.size\n",
    "        np.random.shuffle(train_mask)\n",
    "    \n",
    "    train_index = train_mask[start:end]    \n",
    "    batch = [((train_x[train_index]-mu)/sigma), np.matrix(train_y[train_index]).T]\n",
    "\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1]})\n",
    "\n",
    "        learning_curve.append(train_accuracy)\n",
    "        print(\"step %-6d: train_acc = %-9g, cross entropy = %-10f\"\n",
    "              %(i, train_accuracy, cross_entropy.eval(feed_dict={x:batch[0], y_: batch[1]})))\n",
    "        \n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "print(\"finish\")\n",
    "\n",
    "plt.plot(learning_curve)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "for i in range(40000):\n",
    "    start = (i%40000)*10\n",
    "    end = start + 10\n",
    "    batch = [((train_x[start:end]-mu)/sigma), train_y[start:end]]\n",
    "\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1]})\n",
    "    train_acc.append(train_accuracy)\n",
    "print(sum(train_acc)/len(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = SAT_4['test_x']\n",
    "test_y = SAT_4['test_y']\n",
    "\n",
    "test_acc = []\n",
    "for i in range(10000):\n",
    "    start = i*10\n",
    "    end = start+10\n",
    "    test_acc.append(accuracy.eval(\n",
    "        feed_dict={x:((test_x[start:end]-mu)/sigma), y_:test_y[start:end]}))\n",
    "    \n",
    "print(sum(test_acc)/len(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close() #finish the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
