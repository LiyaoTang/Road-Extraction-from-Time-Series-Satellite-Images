{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.metrics as skmt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import skimage.io\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "sys.path.append('../Metric/')\n",
    "sys.path.append('../../Visualization/')\n",
    "sys.path.append('../../Data_Preprocessing//')\n",
    "from Metric import *\n",
    "from Visualization import *\n",
    "from Data_Extractor import *\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "path_image_dir = \"../../Data/090085/\"\n",
    "path_road_mask = \"../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/road_mask.tif\"\n",
    "\n",
    "\n",
    "# sk-SGD_weight_m5_p1_e15_r1  \n",
    "# sk-SGD_weight_G0.0001_p0_e15_rNone\n",
    "classifier_type = 'LR'\n",
    "path_model_dir = \"../Segmentation-Central-Pixel/Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/\"\n",
    "model_name = \"sk-SGD_weight_m5_0_p1_e15_r1\"\n",
    "size = 8\n",
    "step = 1\n",
    "\n",
    "path_pred_dir = \"./Result/Pred/\"\n",
    "\n",
    "block_size = size/2 # block to collect road prob\n",
    "\n",
    "use_norm = True\n",
    "if model_name.find(\"_G\") > 0:\n",
    "    norm = \"Gaussian\"\n",
    "elif model_name.find(\"_m\") > 0:\n",
    "    norm = \"mean\"\n",
    "else:\n",
    "    norm = None\n",
    "    use_norm = False\n",
    "\n",
    "image_list = ['090085_20170531.h5',\n",
    "              \n",
    "#               '090085_20160512.h5',\n",
    "              '090085_20160528.h5',\n",
    "#               '090085_20160512.h5',# cloudy\n",
    "              \n",
    "#               '090085_20150510.h5', # little bit cloudy\n",
    "#               '090085_20150526.h5', => too much cloud\n",
    "              '090085_20150611.h5',\n",
    "\n",
    "#               '090085_20140320.h5',\n",
    "#               '090085_20140405.h5',\n",
    "#               '090085_20140421.h5',\n",
    "#               '090085_20140507.h5',# cloudy\n",
    "#               '090085_20140523.h5', => snow cover + too much cloud\n",
    "#               '090085_20140608.h5',\n",
    "#               '090085_20140624.h5',\n",
    "#                   '090085_20140710.h5', # might be alright...\n",
    "              '090085_20140726.h5',\n",
    "              \n",
    "              '090085_20130520.h5']\n",
    "image_list = sorted(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "090085_20130520.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-97201194980c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_image_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mh5f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mraw_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scene'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load raw image\n",
    "for image_name in image_list:\n",
    "    print(image_name)\n",
    "    image_path = path_image_dir + image_name\n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    raw_image = np.array(h5f['scene'])\n",
    "    h5f.close()\n",
    "\n",
    "    show_raw_image(raw_image, size=-1)\n",
    "plt.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier ():\n",
    "    def __init__(self, path, name, classifier_type):\n",
    "        assert classifier_type in set(['LR', 'FCN'])\n",
    "        self.classifier_type = classifier_type\n",
    "        if classifier_type == 'LR':\n",
    "            self.classifier = joblib.load(path+name)\n",
    "            self.pos_idx = int(np.where(self.classifier.classes_ == 1)[0])\n",
    "            self.predict = lambda patch: self.classifier.predict_proba(patch.reshape((1, -1)))[0,self.pos_idx]\n",
    "\n",
    "        else: # FCN\n",
    "            tf.reset_default_graph()\n",
    "            tf.train.import_meta_graph(os.path.dirname(path)+name+'.meta')\n",
    "            sess = tf.InteractiveSession()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, path+name)\n",
    "            \n",
    "            graph = tf.get_default_graph()\n",
    "            self.x = graph.get_tensor_by_name(\"input/x:0\")\n",
    "            self.is_training = graph.get_tensor_by_name(\"input/is_training:0\")\n",
    "            self.prob_out = graph.get_tensor_by_name(\"prob_out/prob_out:0\")\n",
    "            \n",
    "            self.predict = lambda patch: self.prob_out.eval(feed_dict={self.x: patch.transpose((0, 2, 3, 1)), \n",
    "                                                                       self.is_training: False})[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load classifier\n",
    "classifier = Classifier(path_model_dir, model_name, classifier_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Result/Pred/sk-SGD_weight_m5_0_p1_e15_r1.h5\n",
      "../../Data/090085/090085_20130520.h5 already predicted, skip\n",
      "../../Data/090085/090085_20140726.h5 already predicted, skip\n",
      "../../Data/090085/090085_20150611.h5 already predicted, skip\n",
      "../../Data/090085/090085_20160528.h5 already predicted, skip\n",
      "../../Data/090085/090085_20170531.h5 already predicted, skip\n"
     ]
    }
   ],
   "source": [
    "path_pred_in_time = path_pred_dir + model_name + '.h5'\n",
    "print(path_pred_in_time)\n",
    "\n",
    "for image_name in image_list[:]:\n",
    "    gc.collect()\n",
    "\n",
    "    date = image_name.split('.')[0].split('_')[-1]\n",
    "    image_path = path_image_dir + image_name\n",
    "\n",
    "    # check prediction not existing\n",
    "    h5f = h5py.File(path_pred_in_time, 'a')\n",
    "    if date in set([pred for pred in h5f.keys()]):\n",
    "        print(image_path, 'already predicted, skip')\n",
    "        h5f.close()\n",
    "        continue\n",
    "    else:\n",
    "        print('predicting', date)\n",
    "        h5f.close()\n",
    "    \n",
    "    # load raw image\n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    raw_image = np.array(h5f['scene'])\n",
    "    h5f.close()\n",
    "    \n",
    "    # construct extractor\n",
    "    data_extractor = Pred_Data_Extractor(raw_image, step=step, size=size,\n",
    "                                         normalization=norm, classifier_type=classifier_type)\n",
    "    \n",
    "    # pred on image\n",
    "    if classifier_type == 'LR':\n",
    "        pred_road = np.zeros(shape=raw_image[0].shape)\n",
    "        print(pred_road.shape, image_name, date)\n",
    "\n",
    "        for coord, patch in data_extractor.iterate_raw_image_patches_with_coord(norm=use_norm):\n",
    "            pred_road[coord[0]+int(size/2),coord[1]+int(size/2)] = classifier.predict(patch)\n",
    "\n",
    "    else: # FCN        \n",
    "        pred_road = np.zeros(shape=(raw_image.shape[1], raw_image.shape[2], 2))\n",
    "        print(pred_road.shape, image_name, date)\n",
    "\n",
    "        for coord, patch in data_extractor.iterate_raw_image_patches_with_coord(norm=use_norm):\n",
    "            pred_road[coord[0]:coord[0]+size, coord[1]:coord[1]+size] += classifier.predict(patch)\n",
    "            \n",
    "    # save prediction\n",
    "    h5f = h5py.File(path_pred_in_time, 'a')\n",
    "    print([i for i in h5f.items()])\n",
    "    h5f.create_dataset(name=date, data=pred_road)\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze pred along the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(coord, mask, size):\n",
    "    return mask[coord[0]:coord[0]+size, coord[1]:coord[1]+size]\n",
    "\n",
    "def pred_normalization(pred):\n",
    "    pred_norm = pred[:,:,1]/pred.sum(axis=-1)\n",
    "    pred_norm[np.where(pred_norm != pred_norm)] = 0\n",
    "    pred_norm[np.where(pred_norm == np.float('inf'))] = 1\n",
    "    return pred_norm\n",
    "\n",
    "# softmax\n",
    "def pred_softmax(pred):\n",
    "    threshold = 500\n",
    "    pred_exp = pred.copy()\n",
    "    inf_idx = np.where(pred_exp > threshold)\n",
    "    \n",
    "    for x, y in zip(inf_idx[0], inf_idx[1]):\n",
    "        while((pred_exp[x,y] > threshold).any()):\n",
    "            pred_exp[x,y] = pred_exp[x,y] / 10\n",
    "    pred_exp = np.exp(pred_exp[:,:,1])/np.exp(pred_exp).sum(axis=-1)\n",
    "    pred_exp[np.where(pred[:,:,1] == 0)] = 0 # softmax([0,0]) = (0.5, 0.5)\n",
    "    return pred_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load road mask\n",
    "road_mask = skimage.io.imread(path_road_mask)\n",
    "road_proba = {}\n",
    "\n",
    "for image_name in image_list:\n",
    "    gc.collect()\n",
    "\n",
    "    # restore prediction \n",
    "    date = image_name.split('.')[0].split('_')[-1]\n",
    "    h5f = h5py.File(path_pred_in_time, 'r')\n",
    "    pred_road = np.array(h5f[date])\n",
    "    h5f.close()\n",
    "\n",
    "    if classifier_type == 'FCN':\n",
    "        print('normalizing pred')\n",
    "        pred_road = pred_normalization(pred_road)\n",
    "    \n",
    "    # load raw image\n",
    "    image_path = path_image_dir + image_name\n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    raw_image = np.array(h5f['scene'])\n",
    "    h5f.close()\n",
    "    \n",
    "    # construct extractor to scane through the image => collect road probability (according to road mask) \n",
    "    data_extractor = Pred_Data_Extractor(raw_image, step=block_size, size=block_size,\n",
    "                                         normalization=None, is_valid=lambda patch: True)\n",
    "    assert not (date in road_proba)\n",
    "    road_proba[date] = {}\n",
    "    for coord, patch in data_extractor.iterate_raw_image_patches_with_coord(norm=False):\n",
    "        sub_valid_mask = (patch[0][0] != -9999)\n",
    "        sub_road_mask  = (get_patch(coord, road_mask, block_size) == 1)\n",
    "        sub_valid_road_mask = np.logical_and(sub_valid_mask, sub_road_mask)\n",
    "        \n",
    "        # patch should contain some roads\n",
    "        if sub_road_mask.sum() / np.prod(sub_road_mask.shape) < 0.1: continue\n",
    "#         if sub_valid_road_mask.sum() / np.prod(sub_valid_road_mask.shape) > 0.25:        \n",
    "\n",
    "        assert not (coord in road_proba[date])\n",
    "        mean_prob = get_patch(coord, pred_road, block_size)[np.where(sub_valid_road_mask)].mean()\n",
    "        road_proba[date][coord] = mean_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coord_list\n",
    "coord_list = sorted(road_proba[date].keys())\n",
    "for image_name in image_list:\n",
    "    date = image_name.split('.')[0].split('_')[-1]\n",
    "    assert ( coord_list == sorted(road_proba[date].keys()) )\n",
    "\n",
    "# get date_list\n",
    "date_list = sorted(road_proba.keys())\n",
    "\n",
    "# construct matrix [date][coord]\n",
    "sorted_road = np.array([[road_proba[date][coord] for coord in coord_list]\n",
    "                        for date in date_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot proba by date\n",
    "plt.figure(figsize=(20, 20))\n",
    "for row, coord in zip((sorted_road.T), coord_list):\n",
    "    valid_row = row[np.where(row == row)]\n",
    "    \n",
    "    # ensure the probability increase\n",
    "    if len(valid_row) > 0 and (np.diff(valid_row) >= 0).all() and (np.diff(valid_row) > 0).any():\n",
    "        plt.plot(row, label=str(coord))\n",
    "        \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appearing_road_coord_list = []\n",
    "for row, coord in zip((sorted_road.T), coord_list):\n",
    "    valid_row = row[np.where(row == row)]\n",
    "    \n",
    "    # ensure the probability increase\n",
    "    if len(valid_row) > 0 and (np.diff(valid_row) >= 0).all() and (np.diff(valid_row) > 0).any():\n",
    "        appearing_road_coord_list.append(coord)\n",
    "        \n",
    "print(len(appearing_road_coord_list), set(appearing_road_coord_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nrows = len(appearing_road_coord_list)\n",
    "ncols = len(image_list)\n",
    "print(nrows, ncols)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(60,240))\n",
    "\n",
    "# from 2014 to 2017\n",
    "for image_name, index in zip(sorted(image_list), range(1,nrows+1)):\n",
    "    \n",
    "    # restore prediction \n",
    "    date = image_name.split('.')[0].split('_')[-1]\n",
    "    h5f = h5py.File(path_pred_in_time, 'r')\n",
    "    pred_road = np.array(h5f[date])\n",
    "    h5f.close()\n",
    "\n",
    "    # load raw image\n",
    "    image_path = path_image_dir + image_name\n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    raw_image = np.array(h5f['scene'])\n",
    "    h5f.close()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    # plot the scene in current date\n",
    "    for coord in appearing_road_coord_list:\n",
    "        plt.title(str(date) + ',' + str(coord))\n",
    "        plt.subplot(nrows, ncols, index)\n",
    "        show_pred_prob_with_raw(raw_image, pred_road, true_road=road_mask, \n",
    "                                coord=coord, size=block_size, show_plot=False)\n",
    "        index += ncols\n",
    "\n",
    "plt.savefig('changing_road')\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_proba_divide = {}\n",
    "divide_num = 4\n",
    "step_size = int(block_size/divide_num)\n",
    "\n",
    "for image_name in image_list:\n",
    "    gc.collect()\n",
    "\n",
    "    # restore prediction \n",
    "    date = image_name.split('.')[0].split('_')[-1]\n",
    "    h5f = h5py.File(path_pred_in_time, 'r')\n",
    "    pred_road = np.array(h5f[date])\n",
    "    h5f.close()\n",
    "\n",
    "    # load raw image\n",
    "    image_path = path_image_dir + image_name\n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    raw_image = np.array(h5f['scene'])\n",
    "    h5f.close()\n",
    "\n",
    "    assert not (date in road_proba_divide)\n",
    "    \n",
    "    for coord in coord_list:\n",
    "        for offset_x in range(divide_num):\n",
    "            offset_x *= step_size\n",
    "\n",
    "            for offset_y in range(divide_num):\n",
    "                offset_y *= step_size\n",
    "                \n",
    "                coord[0] += offset_x\n",
    "                coord[1] += offset_y\n",
    "                \n",
    "                sub_valid_mask = (get_patch(coord, raw_image[0], step_size) != -9999)\n",
    "                sub_road_mask  = (get_patch(coord, road_mask, block_size) == 1)\n",
    "                sub_valid_road_mask = np.logical_and(sub_valid_mask, sub_road_mask)\n",
    "                \n",
    "                if sub_valid_road_mask.sum() / np.prod(sub_valid_road_mask.shape) <  1/100:\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_valid_road_mask.sum() / np.prod(sub_valid_road_mask.shape) < 1/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load road mask\n",
    "road_mask = skimage.io.imread(path_road_mask)\n",
    "road_proba = {}\n",
    "\n",
    "for image_name in image_list:\n",
    "    gc.collect()\n",
    "\n",
    "    # restore prediction \n",
    "    date = image_name.split('.')[0].split('_')[-1]\n",
    "    h5f = h5py.File(path_pred_in_time, 'r')\n",
    "    pred_road = np.array(h5f[date])\n",
    "    h5f.close()\n",
    "\n",
    "    # load raw image\n",
    "    image_path = path_image_dir + image_name\n",
    "    h5f = h5py.File(image_path, 'r')\n",
    "    raw_image = np.array(h5f['scene'])\n",
    "    h5f.close()\n",
    "    \n",
    "    # construct extractor\n",
    "    data_extractor = Pred_Data_Extractor(raw_image, step=block_size, size=block_size,\n",
    "                                         normalization=None, is_valid=lambda patch: True)\n",
    "    assert not (date in road_proba)\n",
    "    road_proba[date] = {}\n",
    "    for coord, patch in data_extractor.iterate_raw_image_patches_with_coord(norm=False):\n",
    "        sub_valid_mask = patch[0][0] != -9999\n",
    "        sub_road_mask  = get_patch(coord, road_mask, block_size) == 1\n",
    "        sub_valid_road_mask = np.logical_and(sub_valid_mask, sub_road_mask)\n",
    "        \n",
    "        assert not (coord in road_proba[date])\n",
    "        mean_prob = get_patch(coord, pred_road, block_size)[np.where(sub_valid_road_mask)].mean()\n",
    "        if mean_prob != mean_prob:\n",
    "            mean_prob = 0\n",
    "        road_proba[date][coord] = mean_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze log pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_pred = -np.log(-pred_road + 1 + 1e-7)\n",
    "print(log_pred.min(), log_pred.max(), log_pred.mean())\n",
    "\n",
    "norm_log_pred = (log_pred - log_pred.min()) / (log_pred.max()-log_pred.min())\n",
    "print(norm_log_pred.min(), norm_log_pred.max(), norm_log_pred.mean())\n",
    "\n",
    "plt.hist(x=norm_log_pred.flatten(), bins=100, histtype='step')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.hist(x=norm_log_pred[np.where(norm_log_pred>0)].flatten(), bins=100, histtype='step')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_road = \"../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/road_mask.tif\"\n",
    "road_mask = skimage.io.imread(path_road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred_road_against_raw(raw_image, norm_log_pred, road_mask, threshold=0.40, figsize=(150,150), show_plot=False,\n",
    "                        save_path=\"123\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array([[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]]), cmap='hot')\n",
    "plt.show()\n",
    "plt.figure(figsize=(100,100))\n",
    "plt.imshow(pred_road, cmap=plt.get_cmap('hot'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array([[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]]), cmap='hot')\n",
    "plt.show()\n",
    "plt.figure(figsize=(100,100))\n",
    "plt.imshow(np.log(pred_road + 1e-9), cmap='hot')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
