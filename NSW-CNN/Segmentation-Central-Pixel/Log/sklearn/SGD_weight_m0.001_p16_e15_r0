Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_m0_001_p16_e15_r0
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 85.953125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6132.546875 MB

SGDClassifier(alpha=0.001, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6132.5703125 MB

 balanced_acc =  0.6281313209551029 AUC =  0.6321630270743959 avg_precision =  0.039105293347132
 balanced_acc =  0.515379548851294 AUC =  0.5178986769745032 avg_precision =  0.02977759169767174
 balanced_acc =  0.5035745857278114 AUC =  0.5041774194133424 avg_precision =  0.028972676567933096
 balanced_acc =  0.5013284516619513 AUC =  0.5018244781378204 avg_precision =  0.02883970897314294
 balanced_acc =  0.5001339480550427 AUC =  0.5002399958644015 avg_precision =  0.02875089258337687
 balanced_acc =  0.5018910694010885 AUC =  0.5024069404340371 avg_precision =  0.02887250981864595
 balanced_acc =  0.5003528890422522 AUC =  0.5004982869546782 avg_precision =  0.028765337196187454
 balanced_acc =  0.5024186832857793 AUC =  0.5030549017103302 avg_precision =  0.028909134860607824
 balanced_acc =  0.5015715399225352 AUC =  0.5021609671148088 avg_precision =  0.028858630424068252
 balanced_acc =  0.5004042782763586 AUC =  0.5006353662178564 avg_precision =  0.02877301614551434
 balanced_acc =  0.5002461685935918 AUC =  0.5004004137541899 avg_precision =  0.0287598616269628
 balanced_acc =  0.5013996441015683 AUC =  0.5018716242813915 avg_precision =  0.028842363984214536
 balanced_acc =  0.5006992583941214 AUC =  0.500938981139417 avg_precision =  0.02879001164275469
 balanced_acc =  0.5016433857611047 AUC =  0.5020944350908374 avg_precision =  0.028854926659964815
 balanced_acc =  0.5011975767627417 AUC =  0.5015005234341189 avg_precision =  0.028821513703261064
finish
mem usage after model trained: 6233.1328125 MB

coefficient info:
shape =  (1, 448)
1.5092330561105414 -0.6802094287843944 0.002109140577383518 0.02727948836146873
On train set
true_pos  = 304779
false_pos = 21169690
true_neg  = 88386
false_neg = 141
size = 21562996
pos_recall    = 0.9995375836284928
pos_precision = 0.014192621014284451
pos_F1        = 0.02798783749167619
neg_recall    = 0.00415776103161923
neg_precision = 0.9984072655799926
neg_F1        = 0.008281036565864836
accuracy      = 0.01823331971123122
balanced_accuracy = 0.5062999432971386
On CV set
true_pos  = 23145
false_pos = 780375
true_neg  = 2043
false_neg = 5
size = 805568
pos_recall    = 0.9997840172786178
pos_precision = 0.028804510155316605
pos_F1        = 0.055995741952653416
neg_recall    = 0.0026111362468654864
neg_precision = 0.99755859375
neg_F1        = 0.005208638742788089
accuracy      = 0.0312673790418686
balanced_accuracy = 0.5131815519526584
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 7800.96875 MB

