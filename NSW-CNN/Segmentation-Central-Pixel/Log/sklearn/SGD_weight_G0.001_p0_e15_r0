Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_m0_001_p0_e15_r0
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 83.94921875 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6131.21875 MB

SGDClassifier(alpha=0.001, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6131.2265625 MB

 balanced_acc =  0.5810961181769754 AUC =  0.5891946400781269 avg_precision =  0.03647615109725791
 balanced_acc =  0.5895939619907975 AUC =  0.6098421229405104 avg_precision =  0.038286693661723895
 balanced_acc =  0.605704865175474 AUC =  0.6312264286465956 avg_precision =  0.041939302273846714
 balanced_acc =  0.5558632629389955 AUC =  0.5778476060204947 avg_precision =  0.034548026316049765
 balanced_acc =  0.5889229498097902 AUC =  0.6133416677723658 avg_precision =  0.03904167667162659
 balanced_acc =  0.5301059869413954 AUC =  0.5348969685915845 avg_precision =  0.03165453957696942
 balanced_acc =  0.6551702001030013 AUC =  0.6865146658362344 avg_precision =  0.0514839084512573
 balanced_acc =  0.6050833400564138 AUC =  0.628280816233811 avg_precision =  0.04308444200412977
 balanced_acc =  0.5591600354678312 AUC =  0.5652575753051126 avg_precision =  0.03469007782964438
 balanced_acc =  0.6465345886521237 AUC =  0.690372099137079 avg_precision =  0.05508820046698493
 balanced_acc =  0.5963533236919584 AUC =  0.6281985327403419 avg_precision =  0.04129940507019801
 balanced_acc =  0.6145630357930069 AUC =  0.6576219192066868 avg_precision =  0.048355007938617627
 balanced_acc =  0.6191230059938188 AUC =  0.6578406747467411 avg_precision =  0.053164871482965295
 balanced_acc =  0.6038716820079606 AUC =  0.626367461042447 avg_precision =  0.04564682771115801
 balanced_acc =  0.6262892661922321 AUC =  0.6686630205293644 avg_precision =  0.05838636433610458
finish
mem usage after model trained: 6140.9140625 MB

coefficient info:
shape =  (1, 448)
0.5271191514103704 -0.2870606126557273 0.0007683264893799123 0.0016580849095276522
On train set
true_pos  = 176177
false_pos = 7128601
true_neg  = 14129475
false_neg = 128743
size = 21562996
pos_recall    = 0.5777810573265119
pos_precision = 0.02411804985723043
pos_F1        = 0.0463032829949362
neg_recall    = 0.6646638670404603
neg_precision = 0.99097061077338
neg_F1        = 0.7956615631124125
accuracy      = 0.6634352666020993
balanced_accuracy = 0.5075443303153052
On CV set
true_pos  = 13004
false_pos = 241884
true_neg  = 540534
false_neg = 10146
size = 805568
pos_recall    = 0.5617278617710583
pos_precision = 0.05101848655095571
pos_F1        = 0.09354117063135255
neg_recall    = 0.6908506706134061
neg_precision = 0.9815755066463282
neg_F1        = 0.8109441316392344
accuracy      = 0.6871400055612934
balanced_accuracy = 0.5162969965986419
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 9098.421875 MB

