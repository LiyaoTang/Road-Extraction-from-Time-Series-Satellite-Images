Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p8_n0_0055_e15_r0
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 85.953125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6341.47265625 MB

SGDClassifier(alpha=0.0055, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6341.58984375 MB

 balanced_acc =  0.5033746292513036 AUC =  0.503374886967088 avg_precision =  0.028927134532312503
 balanced_acc =  0.5088158515656899 AUC =  0.5088066961406735 avg_precision =  0.02932598467331441
 balanced_acc =  0.49967841691089904 AUC =  0.49967841691089904 avg_precision =  0.02871954650957106
 balanced_acc =  0.49989686968459474 AUC =  0.49989686968459474 avg_precision =  0.028731731170072106
 balanced_acc =  0.5087215678911573 AUC =  0.5087355433135404 avg_precision =  0.02929055436133679
 balanced_acc =  0.5053633510167327 AUC =  0.5053627320682192 avg_precision =  0.029185221854943554
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.4999454298972294 AUC =  0.4999454298972294 avg_precision =  0.02873444113022469
 balanced_acc =  0.49995245938785976 AUC =  0.49995245938785976 avg_precision =  0.028734833461669697
 balanced_acc =  0.4990808455575389 AUC =  0.4990808455575389 avg_precision =  0.02868626880057933
 balanced_acc =  0.4992109449906155 AUC =  0.4992109449906155 avg_precision =  0.028693507192064763
 balanced_acc =  0.4999460689418322 AUC =  0.4999460689418322 avg_precision =  0.02873447679627693
 balanced_acc =  0.5068178169190711 AUC =  0.5068172151681728 avg_precision =  0.029229806016803632
 balanced_acc =  0.4998498532270513 AUC =  0.4998498532270513 avg_precision =  0.028729107849363226
 balanced_acc =  0.49996191581254557 AUC =  0.49996191581254557 avg_precision =  0.028735361262576965
finish
mem usage after model trained: 5546.97265625 MB

coefficient info:
shape =  (1, 448)
70.38236641701607 -56.89486868606943 6.315966965119677 326.6026712165557
On train set
true_pos  = 304911
false_pos = 21226445
true_neg  = 31631
false_neg = 9
size = 21562996
pos_recall    = 0.9999704840613931
pos_precision = 0.014161253940532125
pos_F1        = 0.027927014661291147
neg_recall    = 0.0014879521552185627
neg_precision = 0.9997155499367889
neg_F1        = 0.0029714816299099534
accuracy      = 0.015607385912421447
balanced_accuracy = 0.5069384019386605
On CV set
true_pos  = 23148
false_pos = 782410
true_neg  = 8
false_neg = 2
size = 805568
pos_recall    = 0.999913606911447
pos_precision = 0.02873536107890431
pos_F1        = 0.05586527462025224
neg_recall    = 1.0224713644113504e-05
neg_precision = 0.8
neg_F1        = 2.044916592964464e-05
accuracy      = 0.028744935250655437
balanced_accuracy = 0.41436768053945217
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 7838.41015625 MB

