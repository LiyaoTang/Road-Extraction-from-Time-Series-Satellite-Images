Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_G0_001_p6_e15_r1
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 85.95703125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
std =  [125.65067662 147.07994057 235.16274288 262.88676276 927.00557037
 842.7245097  545.23410243]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
std =  [126.38246319 147.99541069 225.10661372 260.4291769  792.72602026
 819.12928051 548.31700647]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6133.734375 MB

SGDClassifier(alpha=0.001, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6133.734375 MB

 balanced_acc =  0.5066482466683678 AUC =  0.7285687551842321 avg_precision =  0.07285103254043025
 balanced_acc =  0.506553029022557 AUC =  0.7311362422831361 avg_precision =  0.07334490697879607
 balanced_acc =  0.5066099039922024 AUC =  0.7297194698538976 avg_precision =  0.07301193513321307
 balanced_acc =  0.505850460515416 AUC =  0.7323686277363786 avg_precision =  0.07399567519593592
 balanced_acc =  0.5067000092811912 AUC =  0.7302709509917273 avg_precision =  0.07312594685256106
 balanced_acc =  0.5058459872031967 AUC =  0.7322070848244397 avg_precision =  0.07408125256093813
 balanced_acc =  0.5063689841769631 AUC =  0.7315829017215044 avg_precision =  0.07364266725120766
 balanced_acc =  0.5061808465750415 AUC =  0.7306098461993826 avg_precision =  0.07346127841256865
 balanced_acc =  0.5064488647523077 AUC =  0.7300066121103109 avg_precision =  0.07319584055369333
 balanced_acc =  0.5057801656091128 AUC =  0.7325810845878249 avg_precision =  0.07415559451735952
 balanced_acc =  0.5058657975858822 AUC =  0.7314928456237677 avg_precision =  0.0738205601247598
 balanced_acc =  0.5058153130622643 AUC =  0.7327321287836692 avg_precision =  0.07421821813653853
 balanced_acc =  0.5057277639516866 AUC =  0.7335323820076465 avg_precision =  0.07441993346646136
 balanced_acc =  0.506078089638353 AUC =  0.7329569842045897 avg_precision =  0.0740922110256981
 balanced_acc =  0.5062712103527413 AUC =  0.7318761646173817 avg_precision =  0.07375059927199495
finish
mem usage after model trained: 6278.13671875 MB

coefficient info:
shape =  (1, 448)
0.5848578840903804 -0.39388738735620965 -0.00011317070443942567 0.0029507615391044873
On train set
true_pos  = 304630
false_pos = 21020068
true_neg  = 238008
false_neg = 290
size = 21562996
pos_recall    = 0.9990489308671127
pos_precision = 0.01428531367712687
pos_F1        = 0.028167857610800155
neg_recall    = 0.011196121417573255
neg_precision = 0.9987830363662306
neg_F1        = 0.022144013683424005
accuracy      = 0.025165241416359767
balanced_accuracy = 0.5065341750216787
On CV set
true_pos  = 23143
false_pos = 772368
true_neg  = 10050
false_neg = 7
size = 805568
pos_recall    = 0.9996976241900648
pos_precision = 0.029091992442593504
pos_F1        = 0.05653866496632917
neg_recall    = 0.012844796515417591
neg_precision = 0.9993039673859003
neg_F1        = 0.025363576138048516
accuracy      = 0.041204466910304285
balanced_accuracy = 0.5141979799142469
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
mem usage after prediction maps calculated: 9273.4609375 MB

