Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p16_n0_1_e15_r1
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 83.95703125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6360.0234375 MB

SGDClassifier(alpha=0.1, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6360.0234375 MB

 balanced_acc =  0.5155607307218586 AUC =  0.5155080627084337 avg_precision =  0.029896041856354763
 balanced_acc =  0.5038102489250151 AUC =  0.5037886481132613 avg_precision =  0.028950534572758372
 balanced_acc =  0.49998441873996335 AUC =  0.4999844080294102 avg_precision =  0.028736617319126613
 balanced_acc =  0.4999708624369842 AUC =  0.4999708624369842 avg_precision =  0.028735860627353553
 balanced_acc =  0.5227780600523823 AUC =  0.5229844397414811 avg_precision =  0.03022920369926648
 balanced_acc =  0.49994351276342114 AUC =  0.49994351276342114 avg_precision =  0.028734334132599276
 balanced_acc =  0.4986921268992744 AUC =  0.49869209791452995 avg_precision =  0.028664663735803664
 balanced_acc =  0.50464469189098 AUC =  0.5046164007377097 avg_precision =  0.02904553356236351
 balanced_acc =  0.49675518960944726 AUC =  0.4967549825755586 avg_precision =  0.02855751695515043
 balanced_acc =  0.5063507542081694 AUC =  0.5063855842369631 avg_precision =  0.029202662964405265
 balanced_acc =  0.4999628133458594 AUC =  0.4999628133458594 avg_precision =  0.028735411358524747
 balanced_acc =  0.514758034221951 AUC =  0.5147321433919805 avg_precision =  0.029704181477928283
 balanced_acc =  0.5042178818128773 AUC =  0.5042514791342938 avg_precision =  0.02901778038896164
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.5059852863941463 AUC =  0.505978737194533 avg_precision =  0.029105375988698907
finish
mem usage after model trained: 5542.55078125 MB

coefficient info:
shape =  (1, 448)
3.108454903859569 -2.1479275757557867 0.330720087608175 0.5175599390507604
On train set
true_pos  = 286106
false_pos = 4978654
true_neg  = 16279422
false_neg = 18814
size = 21562996
pos_recall    = 0.9382985701167519
pos_precision = 0.05434359780882699
pos_F1        = 0.10273696154895792
neg_recall    = 0.7657994072464507
neg_precision = 0.9988456419455455
neg_F1        = 0.8669340056606197
accuracy      = 0.7682386992976301
balanced_accuracy = 0.5265946198771863
On CV set
true_pos  = 2942
false_pos = 90067
true_neg  = 692351
false_neg = 20208
size = 805568
pos_recall    = 0.12708423326133908
pos_precision = 0.03163134750400499
pos_F1        = 0.050654706049466675
neg_recall    = 0.8848863395269536
neg_precision = 0.9716402431237273
neg_F1        = 0.9262363233681855
accuracy      = 0.8631090112814809
balanced_accuracy = 0.5016357953138662
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 8140.96875 MB

