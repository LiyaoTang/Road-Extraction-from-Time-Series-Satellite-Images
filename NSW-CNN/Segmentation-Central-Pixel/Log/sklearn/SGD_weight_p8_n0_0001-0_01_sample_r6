Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p8_n0_0089_e15_r6
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 84.234375 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6359.828125 MB

SGDClassifier(alpha=0.0089, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6359.828125 MB

 balanced_acc =  0.5151092777036477 AUC =  0.5151436519818412 avg_precision =  0.02990803394159063
 balanced_acc =  0.5000031952230137 AUC =  0.5000031952230137 avg_precision =  0.02873766545881576
 balanced_acc =  0.5081821916107252 AUC =  0.5081804002707075 avg_precision =  0.029340252258932945
 balanced_acc =  0.49998031886167005 AUC =  0.49998031886167005 avg_precision =  0.028736388466007796
 balanced_acc =  0.49873276726513976 AUC =  0.4987333967585792 avg_precision =  0.028666956505008882
 balanced_acc =  0.5032191992495635 AUC =  0.5032169307102349 avg_precision =  0.0289306498153159
 balanced_acc =  0.4999660372775724 AUC =  0.4999660372775724 avg_precision =  0.028735591304225618
 balanced_acc =  0.4999505422540515 AUC =  0.4999505422540515 avg_precision =  0.02873472646112206
 balanced_acc =  0.5028169526657648 AUC =  0.5028151657148657 avg_precision =  0.028908521122746896
 balanced_acc =  0.49945946874651476 AUC =  0.49945946874651476 avg_precision =  0.028707344603563903
 balanced_acc =  0.4999815969508756 AUC =  0.4999815969508756 avg_precision =  0.028736459807871255
 balanced_acc =  0.5041243079609328 AUC =  0.5041243079609328 avg_precision =  0.029152946291322267
 balanced_acc =  0.5091873234729 AUC =  0.5091850890527564 avg_precision =  0.029335080962847482
 balanced_acc =  0.5073122655758731 AUC =  0.5073111608982526 avg_precision =  0.029221773391332445
 balanced_acc =  0.4980376661667102 AUC =  0.4980376497144172 avg_precision =  0.0286283645500563
finish
mem usage after model trained: 6504.3828125 MB

coefficient info:
shape =  (1, 448)
48.4882038482218 -36.42715559707919 4.122856711702036 126.78367116909901
On train set
true_pos  = 300874
false_pos = 19184576
true_neg  = 2073500
false_neg = 4046
size = 21562996
pos_recall    = 0.9867309458218549
pos_precision = 0.015440957227059165
pos_F1        = 0.030406101553432305
neg_recall    = 0.09753940102575605
neg_precision = 0.9980525100286588
neg_F1        = 0.17771114050441855
accuracy      = 0.11011336272566205
balanced_accuracy = 0.5067467336278589
On CV set
true_pos  = 22852
false_pos = 775417
true_neg  = 7001
false_neg = 298
size = 805568
pos_recall    = 0.9871274298056155
pos_precision = 0.02862694154476749
pos_F1        = 0.0556403005043711
neg_recall    = 0.00894790252780483
neg_precision = 0.9591724893821071
neg_F1        = 0.017730402156721965
accuracy      = 0.037058324064511004
balanced_accuracy = 0.4938997154634373
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 7931.08203125 MB

