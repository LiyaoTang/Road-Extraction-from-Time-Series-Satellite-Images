Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_m0_0001_p0_e15_rNone
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 87.97265625 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6135.47265625 MB

SGDClassifier(alpha=0.0001, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6135.47265625 MB

 balanced_acc =  0.6580952592955083 AUC =  0.6610454875150367 avg_precision =  0.04338850432268848
 balanced_acc =  0.5714083747482543 AUC =  0.5748119912283661 avg_precision =  0.03446773976889584
 balanced_acc =  0.6004629687399752 AUC =  0.6082638469357717 avg_precision =  0.03827985244172422
 balanced_acc =  0.6441076616633643 AUC =  0.6501064034935793 avg_precision =  0.04557729620945382
 balanced_acc =  0.5906242804364674 AUC =  0.5957097368761037 avg_precision =  0.03658959649895327
 balanced_acc =  0.5254012759813245 AUC =  0.5271115027161715 avg_precision =  0.030510105010167224
 balanced_acc =  0.6458494901061734 AUC =  0.656944523397968 avg_precision =  0.04469679758272807
 balanced_acc =  0.6373363236866528 AUC =  0.6552113664177572 avg_precision =  0.04521653836406966
 balanced_acc =  0.5632091586028485 AUC =  0.568465221097535 avg_precision =  0.03376631315528925
 balanced_acc =  0.6431388778300587 AUC =  0.6658192833925525 avg_precision =  0.046326731798296696
 balanced_acc =  0.5705993015493693 AUC =  0.5861713868654179 avg_precision =  0.035321917841274544
 balanced_acc =  0.6047009545371965 AUC =  0.6273822303321352 avg_precision =  0.04060593462620841
 balanced_acc =  0.5047818486952507 AUC =  0.5200786525883403 avg_precision =  0.02937347151161495
 balanced_acc =  0.6628236355540611 AUC =  0.6775986767542189 avg_precision =  0.0471016882727317
 balanced_acc =  0.5942285992671762 AUC =  0.6081039104135767 avg_precision =  0.038775093400023185
finish
mem usage after model trained: 6280.14453125 MB

coefficient info:
shape =  (1, 448)
5.491534214955028 -2.9510243080623155 0.013924507773894174 0.181518017804741
On train set
true_pos  = 144687
false_pos = 7573858
true_neg  = 13684218
false_neg = 160233
size = 21562996
pos_recall    = 0.47450806768988585
pos_precision = 0.01874537234673115
pos_F1        = 0.036065964019285926
neg_recall    = 0.6437185566558328
neg_precision = 0.9884261932813371
neg_F1        = 0.7796713894700515
accuracy      = 0.6413257693875193
balanced_accuracy = 0.5591133121728593
On CV set
true_pos  = 12597
false_pos = 278298
true_neg  = 504120
false_neg = 10553
size = 805568
pos_recall    = 0.5441468682505399
pos_precision = 0.04330428505130717
pos_F1        = 0.08022417169513923
neg_recall    = 0.6443103302838125
neg_precision = 0.979495718640768
neg_F1        = 0.777308608262643
accuracy      = 0.6414318840867562
balanced_accuracy = 0.5942285992671762
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 9251.6171875 MB

