Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_m10_0_p0_e15_r1
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 83.953125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6131.4765625 MB

SGDClassifier(alpha=10.0, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6131.4765625 MB

 balanced_acc =  0.6736826199859243 AUC =  0.7510534160848338 avg_precision =  0.08831108200309962
 balanced_acc =  0.6685065012533251 AUC =  0.7494311627972225 avg_precision =  0.0892085805821462
 balanced_acc =  0.6458891687306152 AUC =  0.7237729178440339 avg_precision =  0.0821632486108439
 balanced_acc =  0.6779650663935322 AUC =  0.7592878186057623 avg_precision =  0.08969276377309893
 balanced_acc =  0.6602998630810363 AUC =  0.7378880660184364 avg_precision =  0.08221964749388284
 balanced_acc =  0.6717649326518484 AUC =  0.7573599081038955 avg_precision =  0.09140394926658015
 balanced_acc =  0.6651880287020961 AUC =  0.7500493431871968 avg_precision =  0.0911855286594433
 balanced_acc =  0.6706273115230144 AUC =  0.7530787260384428 avg_precision =  0.08978675238171106
 balanced_acc =  0.6667003609075476 AUC =  0.7462149017173969 avg_precision =  0.08690871956546906
 balanced_acc =  0.6669421422598087 AUC =  0.7484174496840158 avg_precision =  0.08870229456246172
 balanced_acc =  0.6714356524844423 AUC =  0.7547764193281383 avg_precision =  0.0903780299707196
 balanced_acc =  0.671101037246959 AUC =  0.7537790987717662 avg_precision =  0.09004807188689863
 balanced_acc =  0.6681064095334479 AUC =  0.7515072947672925 avg_precision =  0.08975072132591663
 balanced_acc =  0.6701516466368557 AUC =  0.754867114525687 avg_precision =  0.0908918517357258
 balanced_acc =  0.6654221495796436 AUC =  0.7463408944262595 avg_precision =  0.08740522630005472
finish
mem usage after model trained: 6269.8515625 MB

coefficient info:
shape =  (1, 448)
0.003943126698892306 -0.0011826293305058837 1.3024179985577045e-05 8.347474741297525e-08
On train set
true_pos  = 251738
false_pos = 10654631
true_neg  = 10603445
false_neg = 53182
size = 21562996
pos_recall    = 0.8255870392234028
pos_precision = 0.02308174242041508
pos_F1        = 0.04490794947842304
neg_recall    = 0.4987960810752582
neg_precision = 0.9950094903387348
neg_F1        = 0.6644865220898343
accuracy      = 0.5034171967568886
balanced_accuracy = 0.5090456163795749
On CV set
true_pos  = 18549
false_pos = 368056
true_neg  = 414362
false_neg = 4601
size = 805568
pos_recall    = 0.8012526997840173
pos_precision = 0.04797920357988127
pos_F1        = 0.09053702822418273
neg_recall    = 0.52959159937527
neg_precision = 0.9890181233187656
neg_F1        = 0.6898094775928701
accuracy      = 0.5373984567410821
balanced_accuracy = 0.5184986634493234
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
mem usage after prediction maps calculated: 9152.546875 MB

