Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_m10_0_p1_e15_r1
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 85.671875 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6133.1953125 MB

SGDClassifier(alpha=10.0, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6133.1953125 MB

 balanced_acc =  0.617300993712425 AUC =  0.7199016294212977 avg_precision =  0.08250690383863322
 balanced_acc =  0.628282494671348 AUC =  0.751062592213239 avg_precision =  0.09001647273981737
 balanced_acc =  0.6324900073989494 AUC =  0.732120027184709 avg_precision =  0.08110371628697648
 balanced_acc =  0.6274841700094496 AUC =  0.744245163800161 avg_precision =  0.08880932452577123
 balanced_acc =  0.6296458211642264 AUC =  0.7610156556431722 avg_precision =  0.09380830818335027
 balanced_acc =  0.6316052465302404 AUC =  0.7375677467746093 avg_precision =  0.08433072047374818
 balanced_acc =  0.6297520747100613 AUC =  0.737390106011675 avg_precision =  0.08472712276240583
 balanced_acc =  0.6319219542749149 AUC =  0.7373568734287612 avg_precision =  0.08376852538775086
 balanced_acc =  0.6282299566476006 AUC =  0.7550994628066848 avg_precision =  0.09227552510067241
 balanced_acc =  0.6311902912678069 AUC =  0.7405393094774975 avg_precision =  0.08590056750708684
 balanced_acc =  0.6289459953868323 AUC =  0.7513086073809171 avg_precision =  0.09041702802629362
 balanced_acc =  0.6322751665108696 AUC =  0.7499744662068715 avg_precision =  0.08834484281723934
 balanced_acc =  0.6308423997475798 AUC =  0.7483122097760995 avg_precision =  0.08869779399749236
 balanced_acc =  0.6329867534141973 AUC =  0.7473115287008567 avg_precision =  0.0872698984296081
 balanced_acc =  0.6336635304124253 AUC =  0.7546025723093874 avg_precision =  0.0898026579686897
finish
mem usage after model trained: 6251.12109375 MB

coefficient info:
shape =  (1, 448)
0.0037297398282117923 -0.0011318529209053156 1.1928996323841217e-05 7.461261886462566e-08
On train set
true_pos  = 283435
false_pos = 14722658
true_neg  = 6535418
false_neg = 21485
size = 21562996
pos_recall    = 0.9295388954479864
pos_precision = 0.01888799436335627
pos_F1        = 0.0370236770094833
neg_recall    = 0.30743224363296096
neg_precision = 0.99672330061921
neg_F1        = 0.46992075744511613
accuracy      = 0.31622938667706474
balanced_accuracy = 0.5078056474912831
On CV set
true_pos  = 21768
false_pos = 526548
true_neg  = 255870
false_neg = 1382
size = 805568
pos_recall    = 0.9403023758099353
pos_precision = 0.03969973518919747
pos_F1        = 0.07618301001284417
neg_recall    = 0.32702468501491533
neg_precision = 0.99462783574083
neg_F1        = 0.49221387555666696
accuracy      = 0.34464874473663304
balanced_accuracy = 0.5171637854650137
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
mem usage after prediction maps calculated: 8825.91796875 MB

