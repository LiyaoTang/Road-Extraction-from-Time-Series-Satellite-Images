Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p16_n1_2_e15_r0
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 87.94921875 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6158.2890625 MB

SGDClassifier(alpha=1.2, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6158.3984375 MB

 balanced_acc =  0.5086587732981515 AUC =  0.5086512925564577 avg_precision =  0.02923586734724018
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.5085159028002283 AUC =  0.5087776541445008 avg_precision =  0.029306931678584107
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.49877823279041705 AUC =  0.498779599655754 avg_precision =  0.028669508875235818
 balanced_acc =  0.5053347302655118 AUC =  0.5054019077935434 avg_precision =  0.029377732935664286
 balanced_acc =  0.49881725039705926 AUC =  0.49882134972326214 avg_precision =  0.028671860282493647
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.4997706691137078 AUC =  0.49977133617689684 avg_precision =  0.028724725937777314
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.49864873646086016 AUC =  0.49865133586794713 avg_precision =  0.028662389922807032
 balanced_acc =  0.4998240257770552 AUC =  0.49982402505933776 avg_precision =  0.028727666988886534
 balanced_acc =  0.4999790407724645 AUC =  0.49997904080006905 avg_precision =  0.028736317126039558
 balanced_acc =  0.49946361892024077 AUC =  0.4994643024357228 avg_precision =  0.028707610202904507
finish
mem usage after model trained: 6299.2421875 MB

coefficient info:
shape =  (1, 448)
0.24799820785886537 -0.19326641273116724 0.026399018301524236 0.003624831491135521
On train set
true_pos  = 303748
false_pos = 19716745
true_neg  = 1541331
false_neg = 1172
size = 21562996
pos_recall    = 0.9961563688836416
pos_precision = 0.01517185415963533
pos_F1        = 0.029888494762689444
neg_recall    = 0.07250566796355418
neg_precision = 0.9992401959672039
neg_F1        = 0.1352010402893716
accuracy      = 0.08556691287240419
balanced_accuracy = 0.5072060250634196
On CV set
true_pos  = 23038
false_pos = 779472
true_neg  = 2946
false_neg = 112
size = 805568
pos_recall    = 0.9951619870410368
pos_precision = 0.0287074304370039
pos_F1        = 0.05580505292735508
neg_recall    = 0.003765250799444798
neg_precision = 0.9633747547416612
neg_F1        = 0.007501183995437162
accuracy      = 0.03225550170811154
balanced_accuracy = 0.49604109258933254
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 8769.0078125 MB

