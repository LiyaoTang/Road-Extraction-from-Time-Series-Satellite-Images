Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p8_n0_0002_e15_r9
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 84.234375 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6359.82421875 MB

SGDClassifier(alpha=0.0002, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6359.82421875 MB

 balanced_acc =  0.5041788129170397 AUC =  0.5041788129170397 avg_precision =  0.028972707349311424
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.499988253062789 AUC =  0.499988253062789 avg_precision =  0.028736831352165575
 balanced_acc =  0.506583984950414 AUC =  0.5065834238609714 avg_precision =  0.02914807418979219
 balanced_acc =  0.5074837878524958 AUC =  0.5074837878524958 avg_precision =  0.02924971486230969
 balanced_acc =  0.5044903083213264 AUC =  0.5044896865295476 avg_precision =  0.029107789031159525
 balanced_acc =  0.5121951131864483 AUC =  0.5121951131864483 avg_precision =  0.029528368999957984
 balanced_acc =  0.5033825575450556 AUC =  0.5033825575450556 avg_precision =  0.0289437002981514
 balanced_acc =  0.4992485768504301 AUC =  0.4992485768504301 avg_precision =  0.028695601489887586
 balanced_acc =  0.5000044733122193 AUC =  0.5000044733122193 avg_precision =  0.0287377368070202
 balanced_acc =  0.5063128353717807 AUC =  0.5063128353717807 avg_precision =  0.0291698524992773
 balanced_acc =  0.5049467952443178 AUC =  0.5049467952443178 avg_precision =  0.02904832902075128
 balanced_acc =  0.4994031968251801 AUC =  0.4994031968251801 avg_precision =  0.0287042105273516
 balanced_acc =  0.5000006390446028 AUC =  0.5000006390446028 avg_precision =  0.028737522763469706
 balanced_acc =  0.5028032097010317 AUC =  0.5028032097010317 avg_precision =  0.028906441110612215
finish
mem usage after model trained: 6504.34375 MB

coefficient info:
shape =  (1, 448)
2133.061384240862 -1567.9853321057356 184.04832394236044 245525.7334624738
On train set
true_pos  = 273758
false_pos = 3735029
true_neg  = 17523047
false_neg = 31162
size = 21562996
pos_recall    = 0.8978027023481568
pos_precision = 0.06828948507366443
pos_F1        = 0.1269247076818152
neg_recall    = 0.82430070341267
neg_precision = 0.9982248132057674
neg_F1        = 0.9029639455651735
accuracy      = 0.8253400872494713
balanced_accuracy = 0.5332571491397159
On CV set
true_pos  = 1708
false_pos = 53340
true_neg  = 729078
false_neg = 21442
size = 805568
pos_recall    = 0.07377969762419007
pos_precision = 0.031027466937945065
pos_F1        = 0.0436839816875112
neg_recall    = 0.9318267217778732
neg_precision = 0.9714304748707563
neg_F1        = 0.95121655278948
accuracy      = 0.9071686064987686
balanced_accuracy = 0.5012289709043507
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 8698.546875 MB

