Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p8_n0_0044_e15_r2
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 85.94921875 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6362.0546875 MB

SGDClassifier(alpha=0.0044, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6362.0546875 MB

 balanced_acc =  0.5042596053248387 AUC =  0.5042598370371668 avg_precision =  0.028977339103061408
 balanced_acc =  0.5044950766706391 AUC =  0.5044927044487392 avg_precision =  0.029023067431247496
 balanced_acc =  0.49968008991034585 AUC =  0.49968008753635723 avg_precision =  0.028719639789096606
 balanced_acc =  0.5037387638775023 AUC =  0.5037381745762418 avg_precision =  0.02896767408485279
 balanced_acc =  0.5071816562321311 AUC =  0.5071798971065865 avg_precision =  0.02922007545005826
 balanced_acc =  0.5022589874473807 AUC =  0.5022589874473808 avg_precision =  0.028876512471371737
 balanced_acc =  0.4999790407724645 AUC =  0.4999790407724645 avg_precision =  0.028736317124498582
 balanced_acc =  0.5000006390446028 AUC =  0.5000006390446028 avg_precision =  0.028737522763469706
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.49987514216810097 AUC =  0.49987514216810097 avg_precision =  0.028730518805832144
 balanced_acc =  0.4984551993047062 AUC =  0.4984551993047062 avg_precision =  0.02865151143590404
 balanced_acc =  0.5054502046590719 AUC =  0.50544848379339 avg_precision =  0.02907682828568691
 balanced_acc =  0.5052955124156926 AUC =  0.5052943324329459 avg_precision =  0.029078845554095366
 balanced_acc =  0.5057887752375897 AUC =  0.5057887752375897 avg_precision =  0.029227648460691053
 balanced_acc =  0.5056875261149096 AUC =  0.5056875261149096 avg_precision =  0.02924113188397498
finish
mem usage after model trained: 6506.3203125 MB

coefficient info:
shape =  (1, 448)
92.34898480807392 -71.30700367543375 8.567934202508862 504.75526878048447
On train set
true_pos  = 242944
false_pos = 2080592
true_neg  = 19177484
false_neg = 61976
size = 21562996
pos_recall    = 0.7967466876557786
pos_precision = 0.10455788074727485
pos_F1        = 0.18485681327745263
neg_recall    = 0.9021269845869401
neg_precision = 0.9967787037681931
neg_F1        = 0.9470938676367867
accuracy      = 0.9006368131775381
balanced_accuracy = 0.550668292257734
On CV set
true_pos  = 692
false_pos = 14488
true_neg  = 767930
false_neg = 22458
size = 805568
pos_recall    = 0.029892008639308857
pos_precision = 0.0455862977602108
pos_F1        = 0.036107487607618054
neg_recall    = 0.9814830435905104
neg_precision = 0.9715861070765245
neg_F1        = 0.9765094995822753
accuracy      = 0.9541367085087789
balanced_accuracy = 0.5085862024183676
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 9110.77734375 MB

