Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p8_n0_0097_e15_r4
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 83.984375 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6360.05859375 MB

SGDClassifier(alpha=0.0097, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6360.05859375 MB

 balanced_acc =  0.503550948033848 AUC =  0.5035519663093256 avg_precision =  0.028937139071396577
 balanced_acc =  0.5137165993814811 AUC =  0.5137493986286639 avg_precision =  0.02964753148737166
 balanced_acc =  0.49996127676794283 AUC =  0.49996127676794283 avg_precision =  0.02873532559432853
 balanced_acc =  0.5030105472393172 AUC =  0.5030272840797063 avg_precision =  0.028922244731061766
 balanced_acc =  0.4999599986787373 AUC =  0.4999599986787373 avg_precision =  0.028735254258097323
 balanced_acc =  0.498403321801877 AUC =  0.498403321801877 avg_precision =  0.028648633313159026
 balanced_acc =  0.5042211990478628 AUC =  0.5042199827927786 avg_precision =  0.02902121666734396
 balanced_acc =  0.49908382535489043 AUC =  0.49908382121421263 avg_precision =  0.028686434659079926
 balanced_acc =  0.502852351982543 AUC =  0.5028489259857547 avg_precision =  0.02890545513915234
 balanced_acc =  0.4999499032094487 AUC =  0.4999499032094487 avg_precision =  0.028734690794449957
 balanced_acc =  0.510875995771584 AUC =  0.5108727845931585 avg_precision =  0.02943534796529513
 balanced_acc =  0.5048047124137249 AUC =  0.5048035870327156 avg_precision =  0.02902842875887927
 balanced_acc =  0.4987571586728757 AUC =  0.4987571586728757 avg_precision =  0.028668275849535636
 balanced_acc =  0.4999090258863967 AUC =  0.4999090258863967 avg_precision =  0.02873240951372883
 balanced_acc =  0.4999321392049271 AUC =  0.4999321392049271 avg_precision =  0.02873369937654499
finish
mem usage after model trained: 6504.3671875 MB

coefficient info:
shape =  (1, 448)
43.150527834774756 -33.41413428806854 3.653794138440511 106.13911440069798
On train set
true_pos  = 304893
false_pos = 21170359
true_neg  = 87717
false_neg = 27
size = 21562996
pos_recall    = 0.9999114521841794
pos_precision = 0.014197411979146974
pos_F1        = 0.027997299562188948
neg_recall    = 0.0041262906389082435
neg_precision = 0.9996922866520788
neg_F1        = 0.008218658266583339
accuracy      = 0.018207581172857427
balanced_accuracy = 0.5069448493156129
On CV set
true_pos  = 23146
false_pos = 782389
true_neg  = 29
false_neg = 4
size = 805568
pos_recall    = 0.9998272138228942
pos_precision = 0.028733698721967387
pos_F1        = 0.055861998226105214
neg_recall    = 3.706458695991146e-05
neg_precision = 0.8787878787878788
neg_F1        = 7.412604750968433e-05
accuracy      = 0.028768521093191387
balanced_accuracy = 0.4537607887549231
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 9090.26953125 MB

