Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_p8_n0_0009_e15_r7
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 84.234375 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6359.82421875 MB

SGDClassifier(alpha=0.0009, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6359.82421875 MB

 balanced_acc =  0.5128435593361085 AUC =  0.5128533796435569 avg_precision =  0.02947628294060626
 balanced_acc =  0.5097994987759246 AUC =  0.5097989087845511 avg_precision =  0.029464924481648745
 balanced_acc =  0.4991985015361942 AUC =  0.4991985015361942 avg_precision =  0.02869281488255631
 balanced_acc =  0.5088000374339354 AUC =  0.508780921912189 avg_precision =  0.0292372257321334
 balanced_acc =  0.49881663984031954 AUC =  0.49881663984031954 avg_precision =  0.028671583215501333
 balanced_acc =  0.49991309711119986 AUC =  0.49991309711119986 avg_precision =  0.02873263670385359
 balanced_acc =  0.49883996880534826 AUC =  0.49883996880534826 avg_precision =  0.028672876888772646
 balanced_acc =  0.5049930065884753 AUC =  0.5049930065884752 avg_precision =  0.029229467392502383
 balanced_acc =  0.5043986089266045 AUC =  0.5043986089266046 avg_precision =  0.02914982454887533
 balanced_acc =  0.499683866760564 AUC =  0.499683866760564 avg_precision =  0.028719850345261227
 balanced_acc =  0.49991629233421364 AUC =  0.49991629233421364 avg_precision =  0.028732815012595735
 balanced_acc =  0.5024002021710766 AUC =  0.5024002021710766 avg_precision =  0.028882178428867644
 balanced_acc =  0.5054779912017443 AUC =  0.5054779912017443 avg_precision =  0.029288939405039533
 balanced_acc =  0.5 AUC =  0.5 avg_precision =  0.028737487089854612
 balanced_acc =  0.503942144363273 AUC =  0.5039415174922629 avg_precision =  0.02910547792670161
finish
mem usage after model trained: 6504.3828125 MB

coefficient info:
shape =  (1, 448)
451.68245612419116 -358.5532535103469 42.02658729792506 12293.936692129286
On train set
true_pos  = 205444
false_pos = 1408644
true_neg  = 19849432
false_neg = 99476
size = 21562996
pos_recall    = 0.6737636101272465
pos_precision = 0.12728178389282369
pos_F1        = 0.21411479264286548
neg_recall    = 0.9337360540060163
neg_precision = 0.9950134613884629
neg_F1        = 0.9634013496352948
accuracy      = 0.9300598117256063
balanced_accuracy = 0.5611476226406433
On CV set
true_pos  = 441
false_pos = 8736
true_neg  = 773682
false_neg = 22709
size = 805568
pos_recall    = 0.019049676025917926
pos_precision = 0.04805491990846682
pos_F1        = 0.027283694744331365
neg_recall    = 0.988834612700628
neg_precision = 0.9714851122124685
neg_F1        = 0.9800830879479405
accuracy      = 0.9609654306030031
balanced_accuracy = 0.5097700160604677
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 8483.3046875 MB

