Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_G0_1_p0_e15_r0
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 83.98828125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
std =  [125.65067662 147.07994057 235.16274288 262.88676276 927.00557037
 842.7245097  545.23410243]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
std =  [126.38246319 147.99541069 225.10661372 260.4291769  792.72602026
 819.12928051 548.31700647]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6131.484375 MB

SGDClassifier(alpha=0.1, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6131.484375 MB

 balanced_acc =  0.6089632424691409 AUC =  0.6754332140779489 avg_precision =  0.0597237466290563
 balanced_acc =  0.6093514297956337 AUC =  0.6757871451355646 avg_precision =  0.05970706466614786
 balanced_acc =  0.6093500081077231 AUC =  0.6765225781469701 avg_precision =  0.05979043883078813
 balanced_acc =  0.6102642726857811 AUC =  0.6810035317938659 avg_precision =  0.06034444211083719
 balanced_acc =  0.6097601455535466 AUC =  0.6769340636318492 avg_precision =  0.05985177831028939
 balanced_acc =  0.6097699251167259 AUC =  0.6764425147745041 avg_precision =  0.059788372756711394
 balanced_acc =  0.6105647673582002 AUC =  0.6784923384790751 avg_precision =  0.060049874794596766
 balanced_acc =  0.6107755946597115 AUC =  0.6780921264034971 avg_precision =  0.06000029109788019
 balanced_acc =  0.6108418901681687 AUC =  0.6779093564449845 avg_precision =  0.05997752380223063
 balanced_acc =  0.6108376322816117 AUC =  0.6774330976200064 avg_precision =  0.05991629685415032
 balanced_acc =  0.6110153872168345 AUC =  0.6775554247248604 avg_precision =  0.05993255893965178
 balanced_acc =  0.6110756943666802 AUC =  0.6776183606530009 avg_precision =  0.05994142302532411
 balanced_acc =  0.6111016223523327 AUC =  0.6776474887200623 avg_precision =  0.059944843095906565
 balanced_acc =  0.6110231275790245 AUC =  0.6773922565140825 avg_precision =  0.05991285320180324
 balanced_acc =  0.6110073884211423 AUC =  0.6772874561805184 avg_precision =  0.059900215326340815
finish
mem usage after model trained: 6255.08203125 MB

coefficient info:
shape =  (1, 448)
0.013264331372435214 -0.00741802912973595 0.00011641231430087613 6.992676923813865e-06
On train set
true_pos  = 111555
false_pos = 4217797
true_neg  = 17040279
false_neg = 193365
size = 21562996
pos_recall    = 0.36585005903187723
pos_precision = 0.025767135589806513
pos_F1        = 0.048143484025106854
neg_recall    = 0.8015908401117768
neg_precision = 0.9887797960779507
neg_F1        = 0.8853997171339706
accuracy      = 0.795429076738687
balanced_accuracy = 0.5072734658338787
On CV set
true_pos  = 9635
false_pos = 151933
true_neg  = 630485
false_neg = 13515
size = 805568
pos_recall    = 0.4161987041036717
pos_precision = 0.05963433353139236
pos_F1        = 0.10432118147662924
neg_recall    = 0.8058160727386129
neg_precision = 0.9790139751552795
neg_F1        = 0.8840115590240729
accuracy      = 0.7946194486374831
balanced_accuracy = 0.519324154343336
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
mem usage after prediction maps calculated: 9236.28515625 MB

