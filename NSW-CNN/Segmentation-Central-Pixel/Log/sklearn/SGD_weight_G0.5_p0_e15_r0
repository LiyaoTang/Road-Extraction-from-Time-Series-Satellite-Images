Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_G0_5_p0_e15_r0
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 85.97265625 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
std =  [125.65067662 147.07994057 235.16274288 262.88676276 927.00557037
 842.7245097  545.23410243]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
std =  [126.38246319 147.99541069 225.10661372 260.4291769  792.72602026
 819.12928051 548.31700647]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6133.47265625 MB

SGDClassifier(alpha=0.5, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6133.47265625 MB

 balanced_acc =  0.568068236569862 AUC =  0.6103915075427664 avg_precision =  0.04695916145523227
 balanced_acc =  0.5688725711218963 AUC =  0.611046324594455 avg_precision =  0.04714200158330732
 balanced_acc =  0.5692473528108718 AUC =  0.6116103468514924 avg_precision =  0.047290624206683056
 balanced_acc =  0.5699099343510998 AUC =  0.6121721601949612 avg_precision =  0.04742770554598107
 balanced_acc =  0.5694640894668628 AUC =  0.6116991645553213 avg_precision =  0.04731335753191826
 balanced_acc =  0.5692733526234812 AUC =  0.6113305356926784 avg_precision =  0.04722416506105123
 balanced_acc =  0.569581120810474 AUC =  0.611585727596061 avg_precision =  0.04728628771924803
 balanced_acc =  0.5696263637329142 AUC =  0.611648737669938 avg_precision =  0.04730173140989231
 balanced_acc =  0.5696131879306178 AUC =  0.6116027112760543 avg_precision =  0.04729049344045201
 balanced_acc =  0.5696543309195555 AUC =  0.6115712777348188 avg_precision =  0.047283041016700465
 balanced_acc =  0.5696200738225429 AUC =  0.6115592162165151 avg_precision =  0.047280038465287784
 balanced_acc =  0.5695496496718842 AUC =  0.611550336118966 avg_precision =  0.047277791487524576
 balanced_acc =  0.5695537352510369 AUC =  0.6115513358994162 avg_precision =  0.04727812973478231
 balanced_acc =  0.5695676578107672 AUC =  0.6115293493421211 avg_precision =  0.04727282635747943
 balanced_acc =  0.5695581942089065 AUC =  0.6115075685489066 avg_precision =  0.04726746926004074
finish
mem usage after model trained: 6257.07421875 MB

coefficient info:
shape =  (1, 448)
0.0029400304648059825 -0.0015221609251788897 0.00013217093549519878 4.232133869346596e-07
On train set
true_pos  = 104269
false_pos = 5525361
true_neg  = 15732715
false_neg = 200651
size = 21562996
pos_recall    = 0.34195526695526696
pos_precision = 0.018521465886745664
pos_F1        = 0.03513964833053896
neg_recall    = 0.7400817929148433
neg_precision = 0.9874068668227417
neg_F1        = 0.8460395270503359
accuracy      = 0.7344519286652004
balanced_accuracy = 0.5029641663547437
On CV set
true_pos  = 9364
false_pos = 207635
true_neg  = 574783
false_neg = 13786
size = 805568
pos_recall    = 0.40449244060475165
pos_precision = 0.04315227259111793
pos_F1        = 0.07798491769692982
neg_recall    = 0.7346239478130615
neg_precision = 0.9765770878180808
neg_F1        = 0.8384951863146769
accuracy      = 0.7251367978867085
balanced_accuracy = 0.5098646802045994
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
mem usage after prediction maps calculated: 9184.328125 MB

