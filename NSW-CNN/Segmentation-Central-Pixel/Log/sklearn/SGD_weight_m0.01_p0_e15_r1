Train set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_train
CV set: ../../Data/090085/Road_Data/motor_trunk_pri_sec_tert_uncl_track/posneg_topleft_coord_split_8_cv
will be saved as  sk-SGD_weight_m0_01_p0_e15_r1
will be saved into  ./Result/motor_trunk_pri_sec_tert_uncl_track/sklearn/
mem usage before data loaded: 87.2578125 MB

mu =  [ 144.71187809  191.4973748   363.63933132  368.9204473  2385.57259035
 1362.40326606  728.31018062]
mu =  [ 150.8227309   198.28994142  365.46753706  373.66751856 2370.63525823
 1356.64782764  731.00466191]
train data:
(7, 7650, 8091) (7650, 8091)
pos =  304920 neg =  21258076
cv data:
(7, 2365, 8091) (2365, 8091)
pos =  23150 neg =  782418
mem usage after data loaded: 6134.78125 MB

SGDClassifier(alpha=0.01, average=False,
       class_weight={0: 0.014140892109797729, 1: 0.9858591078902023},
       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', max_iter=1, n_iter=None,
       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
       shuffle=False, tol=None, verbose=0, warm_start=False)
classes in classifier  [0 1] 1
mem usage after model created: 6134.78125 MB

 balanced_acc =  0.6293955002437561 AUC =  0.6544948757097446 avg_precision =  0.042740186628605265
 balanced_acc =  0.6439088978676818 AUC =  0.7052570801904692 avg_precision =  0.07279836153870574
 balanced_acc =  0.5150976957862481 AUC =  0.5226376624500378 avg_precision =  0.028959954149768232
 balanced_acc =  0.6179376957957441 AUC =  0.6732172882715628 avg_precision =  0.049933381040287814
 balanced_acc =  0.5730380110299595 AUC =  0.6088593954024133 avg_precision =  0.040643022572789546
 balanced_acc =  0.6249415220083621 AUC =  0.6792044395717685 avg_precision =  0.081941093757511
 balanced_acc =  0.5975131094824409 AUC =  0.6429103415122264 avg_precision =  0.05498140099613594
 balanced_acc =  0.5261000466036043 AUC =  0.561437668249195 avg_precision =  0.040079854187479946
 balanced_acc =  0.5444003185848519 AUC =  0.5812723353748918 avg_precision =  0.036043303007192384
 balanced_acc =  0.6374023483395747 AUC =  0.6994172765098294 avg_precision =  0.06201111857564602
 balanced_acc =  0.5965139744258601 AUC =  0.6430524389732142 avg_precision =  0.058317057858614206
 balanced_acc =  0.6732327532889721 AUC =  0.743969732926339 avg_precision =  0.08932168195717455
 balanced_acc =  0.6346483373436902 AUC =  0.6945950723549488 avg_precision =  0.07273696776027817
 balanced_acc =  0.6281859648723558 AUC =  0.6736308435984462 avg_precision =  0.07266072854414263
 balanced_acc =  0.6448460311882365 AUC =  0.7109264263283681 avg_precision =  0.07611311778373303
finish
mem usage after model trained: 6279.47265625 MB

coefficient info:
shape =  (1, 448)
0.052418642496916704 -0.02908515434620904 8.157842313737172e-05 1.728364635299634e-05
On train set
true_pos  = 208675
false_pos = 8096555
true_neg  = 13161521
false_neg = 96245
size = 21562996
pos_recall    = 0.6843598320871048
pos_precision = 0.02512573402542735
pos_F1        = 0.04847186169811211
neg_recall    = 0.6191303954318349
neg_precision = 0.9927404813148761
neg_F1        = 0.7626365307849075
accuracy      = 0.62005279785796
balanced_accuracy = 0.5089331076701518
On CV set
true_pos  = 14832
false_pos = 274628
true_neg  = 507790
false_neg = 8318
size = 805568
pos_recall    = 0.6406911447084234
pos_precision = 0.051240240447730255
pos_F1        = 0.0948913982278238
neg_recall    = 0.6490009176680496
neg_precision = 0.9838832182411433
neg_F1        = 0.7821021681506569
accuracy      = 0.6487621156749027
balanced_accuracy = 0.5175617293444368
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/localdata/u6142160/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp
  np.exp(prob, prob)
mem usage after prediction maps calculated: 9178.234375 MB

