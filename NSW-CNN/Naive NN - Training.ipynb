{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import scipy.io as sio\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & Reorder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "path = \"../Data/090085/Road_Data/res_serv_road_livi/patch_set.h5\"\n",
    "\n",
    "data = h5py.File(path, 'r')\n",
    "X = np.array(data['image_patch'])\n",
    "Y = np.array(data['road_existence'])\n",
    "Road_patch = np.array(data['road_patch'])\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reorder & Create train-test set\n",
    "index_mask = np.arange(X.shape[0])\n",
    "np.random.shuffle(index_mask)\n",
    "\n",
    "train_mask = index_mask[:int(index_mask.size*0.75)]\n",
    "test_mask = index_mask[int(index_mask.size*0.75):]\n",
    "\n",
    "train_x = X[train_mask].flatten().reshape((train_mask.size, -1))\n",
    "train_y = Y[train_mask]\n",
    "train_road_patch = Road_patch[train_mask]\n",
    "train_mask = np.arange(train_x.shape[0])\n",
    "np.random.shuffle(train_mask)\n",
    "\n",
    "test_x = X[test_mask].flatten().reshape((test_mask.size, -1))\n",
    "test_y = Y[test_mask]\n",
    "test_road_patch = Road_patch[test_mask]\n",
    "test_mask = np.arange(test_x.shape[0])\n",
    "np.random.shuffle(test_mask)\n",
    "\n",
    "print(train_x.shape, train_y.shape, train_road_patch.shape)\n",
    "print(test_x.shape, test_y.shape, test_road_patch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 28\n",
    "height = 28\n",
    "band = 7\n",
    "\n",
    "L1_out = 512\n",
    "L2_out = 256\n",
    "L3_out = 128\n",
    "L4_out = 64\n",
    "class_output = 1 # number of possible classifications for the problem\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 9e-6\n",
    "iteration = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Normalization Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize Parameters\n",
    "mu = train_x.mean(axis=0, keepdims=True)\n",
    "sigma = 0\n",
    "for img in train_x:\n",
    "    sigma += (img-mu)**2\n",
    "sigma /= train_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_i$ is the raw number (int)\n",
    "\n",
    "$\\mu = \\frac 1 n \\sum_{i=1}^n \\frac {a_i} {\\text{Max}} = \\frac 1 {\\text{Max}}(\\frac 1 n \\sum_{i=1}^n a_i)$\n",
    "\n",
    "$\\sigma = \\sqrt{\\frac 1 n \\sum_{i=1}^n (\\frac{a_i}{\\text{Max}}-\\mu)^2 } = \\frac 1 {\\text{Max}} \\sqrt{\\frac 1 n \\sum_{i=1}^n(a_i-\\mu*\\text{Max})^2 } $\n",
    "\n",
    "$\\displaystyle \\frac {\\frac A {\\text{Max}} - mu} {\\sigma} = \\frac {A-\\mu *\\text{Max}}{\\sigma *\\text{Max}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place holders for inputs and outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, width*height*band])\n",
    "y = tf.placeholder(tf.float32, shape=[None, class_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([width*height*band, L1_out], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.truncated_normal([L1_out], stddev=0.1))\n",
    "\n",
    "fc1=tf.matmul(x, W_fc1) + b_fc1 # applying weights and biases\n",
    "h_fc1 = tf.nn.relu(fc1) # ReLU activation\n",
    "\n",
    "# Layer 2\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([L1_out, L2_out], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.truncated_normal([L2_out], stddev=0.1))\n",
    "\n",
    "fc2=tf.matmul(h_fc1, W_fc2) + b_fc2# applying weights and biases\n",
    "h_fc2 = tf.nn.relu(fc2) # ReLU activation\n",
    "\n",
    "# Layer 3\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([L2_out, L3_out], stddev=0.1))\n",
    "b_fc3 = tf.Variable(tf.truncated_normal([L3_out], stddev=0.1))\n",
    "\n",
    "fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(fc3) # ReLU activation\n",
    "\n",
    "# Layer 4\n",
    "W_fc4 = tf.Variable(tf.truncated_normal([L3_out, L4_out], stddev=0.1))\n",
    "b_fc4 = tf.Variable(tf.truncated_normal([L4_out], stddev=0.1))\n",
    "\n",
    "fc4=tf.matmul(h_fc3, W_fc4) + b_fc4\n",
    "h_fc4 = tf.nn.relu(fc4) # ReLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer (Softmax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc_out = tf.Variable(tf.truncated_normal([L4_out, class_output], stddev=0.1))\n",
    "b_fc_out = tf.Variable(tf.truncated_normal([class_output], stddev=0.1))\n",
    "\n",
    "fc_out=tf.matmul(h_fc4, W_fc_out) + b_fc_out\n",
    "\n",
    "y_CNN= tf.sigmoid(fc_out)\n",
    "prediction = tf.cast(tf.round(y_CNN), tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function & optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum((y * tf.log(y_CNN) + (1-y) * tf.log(1-y_CNN)), axis=1))\n",
    "cross_entropy_sum = -tf.reduce_sum(y * tf.log(y_CNN)+(1-y) * tf.log(1-y_CNN))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y, tf.round(y_CNN)), \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & monitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = int(train_mask.size/batch_size)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"start\")\n",
    "learning_curve = []\n",
    "F1_curve = []\n",
    "for i in range(iteration):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > train_mask.size:\n",
    "        end = train_mask.size\n",
    "        np.random.shuffle(train_mask)\n",
    "    \n",
    "    train_index = train_mask[start:end]    \n",
    "    batch = [((train_x[train_index]-mu)/sigma), np.matrix(train_y[train_index]).astype(int).T]\n",
    "\n",
    "    # snap shot\n",
    "    if i%1000 == 0:\n",
    "        pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "        \n",
    "        # compute metric\n",
    "        true_neg = np.logical_and(pred == batch[1], np.logical_not(batch[1])).sum()\n",
    "        false_neg = (np.logical_not(batch[1]).sum()) - true_neg\n",
    "        true_pos = (np.logical_and(pred == batch[1], batch[1])).sum()\n",
    "        false_pos = batch[1].sum() - true_pos\n",
    "\n",
    "        precision = true_neg / (true_neg + false_neg)\n",
    "        recall = true_neg / (true_neg + false_pos)\n",
    "        \n",
    "        train_F1_score = 2*(recall*precision) / (recall+precision)\n",
    "        \n",
    "        learning_curve.append(train_accuracy)\n",
    "        F1_curve.append(train_F1_score)\n",
    "        \n",
    "#         print(\"step %-6d: train_acc = %-9g, cross entropy = %-10f, F1 = %-10f\"\n",
    "#               %(i, train_accuracy, cross_entropy.eval(feed_dict={x:batch[0], y: batch[1]}), train_F1_score))\n",
    "        \n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1]})\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training curve\n",
    "fig, subfig = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(18,5))\n",
    "subfig[0].plot(learning_curve)\n",
    "subfig[0].set_title('learning_curve')\n",
    "    \n",
    "subfig[1].plot(F1_curve)\n",
    "subfig[1].set_title('F1_curve')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "train_F1 = []\n",
    "train_pred_label = np.zeros(train_mask.size)\n",
    "\n",
    "batch_num = int(train_mask.size/batch_size)+1\n",
    "for i in range(batch_num):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > train_mask.size:\n",
    "        end = train_mask.size\n",
    "    \n",
    "    batch = [((train_x[start:end]-mu)/sigma), np.matrix(train_y[start:end]).T]\n",
    "\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "    train_acc.append(train_accuracy * (end-start))\n",
    "    \n",
    "    # compute metric   \n",
    "    pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "\n",
    "    train_pred_label[start:end] = pred.T\n",
    "    \n",
    "    true_neg = np.logical_and(pred == batch[1], np.logical_not(batch[1])).sum()\n",
    "    false_neg = (np.logical_not(batch[1]).sum()) - true_neg\n",
    "    true_pos = (np.logical_and(pred == batch[1], batch[1])).sum()\n",
    "    false_pos = batch[1].sum() - true_pos\n",
    "    \n",
    "    precision = true_neg / (true_neg + false_neg)\n",
    "    recall = true_neg / (true_neg + false_pos)     \n",
    "\n",
    "    train_F1.append(2*(recall*precision) / (recall+precision)* (end-start))\n",
    "            \n",
    "print(\"train_acc\", sum(train_acc)/train_mask.size, \" train_F1 = \", sum(train_F1)/train_mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "test_F1 = []\n",
    "test_pred_label = np.zeros(test_mask.size)\n",
    "\n",
    "print(test_mask.size)\n",
    "\n",
    "batch_num = int(test_mask.size/batch_size)+1\n",
    "for i in range(batch_num):\n",
    "    start = i%batch_num * batch_size\n",
    "    end = start + batch_size\n",
    "\n",
    "    if end > test_mask.size:\n",
    "        end = test_mask.size\n",
    "    \n",
    "    batch = [((test_x[start:end]-mu)/sigma), np.matrix(test_y[start:end]).T]\n",
    "\n",
    "    test_accuracy = accuracy.eval(feed_dict={x:batch[0], y: batch[1]})\n",
    "    test_acc.append(test_accuracy * (end-start))\n",
    "\n",
    "    # compute metric   \n",
    "    pred = prediction.eval(feed_dict={x:batch[0], y: batch[1]})        \n",
    "\n",
    "    test_pred_label[start:end] = pred.T\n",
    "    \n",
    "    true_neg = np.logical_and(pred == batch[1], np.logical_not(batch[1])).sum()\n",
    "    false_neg = (np.logical_not(batch[1]).sum()) - true_neg\n",
    "    true_pos = (np.logical_and(pred == batch[1], batch[1])).sum()\n",
    "    false_pos = batch[1].sum() - true_pos\n",
    "    \n",
    "    precision = true_neg / (true_neg + false_neg)\n",
    "    recall = true_neg / (true_neg + false_pos)     \n",
    "\n",
    "    test_F1.append(2*(recall*precision) / (recall+precision)* (end-start))\n",
    "    \n",
    "print(\"test_acc = \", sum(test_acc)/test_mask.size, \"test_F1 = \", sum(test_F1)/test_mask.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = './Result/res_serv_road_livi'\n",
    "saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred_pos = np.where(train_pred_label == 1)[0]\n",
    "train_pred_neg = np.where(train_pred_label == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
